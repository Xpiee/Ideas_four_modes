{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import lightgbm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training_Code.config import SELECTCOLS, ECG_SELECTCOLS, EDA_SELECTCOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1030.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.61      0.58        38\n",
      "           1       0.87      0.85      0.86       122\n",
      "\n",
      "    accuracy                           0.79       160\n",
      "   macro avg       0.72      0.73      0.72       160\n",
      "weighted avg       0.80      0.79      0.80       160\n",
      "\n",
      "Test Subject: 1105.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.94      0.61        31\n",
      "           1       0.98      0.73      0.83       128\n",
      "\n",
      "    accuracy                           0.77       159\n",
      "   macro avg       0.72      0.83      0.72       159\n",
      "weighted avg       0.88      0.77      0.79       159\n",
      "\n",
      "Test Subject: 1106.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.33      0.25        24\n",
      "           1       0.87      0.77      0.82       136\n",
      "\n",
      "    accuracy                           0.71       160\n",
      "   macro avg       0.54      0.55      0.54       160\n",
      "weighted avg       0.77      0.71      0.73       160\n",
      "\n",
      "Test Subject: 1241.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.35      0.51       129\n",
      "           1       0.26      0.94      0.41        32\n",
      "\n",
      "    accuracy                           0.47       161\n",
      "   macro avg       0.61      0.64      0.46       161\n",
      "weighted avg       0.82      0.47      0.49       161\n",
      "\n",
      "Test Subject: 1271.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.40      0.30        30\n",
      "           1       0.81      0.66      0.73       113\n",
      "\n",
      "    accuracy                           0.61       143\n",
      "   macro avg       0.52      0.53      0.51       143\n",
      "weighted avg       0.69      0.61      0.64       143\n",
      "\n",
      "Test Subject: 1314.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.52      0.58        21\n",
      "           1       0.92      0.95      0.93       121\n",
      "\n",
      "    accuracy                           0.89       142\n",
      "   macro avg       0.78      0.74      0.76       142\n",
      "weighted avg       0.88      0.89      0.88       142\n",
      "\n",
      "Test Subject: 1323.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.32      0.48        85\n",
      "           1       0.49      0.98      0.65        56\n",
      "\n",
      "    accuracy                           0.58       141\n",
      "   macro avg       0.73      0.65      0.56       141\n",
      "weighted avg       0.77      0.58      0.55       141\n",
      "\n",
      "Test Subject: 1337.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.44      0.60       136\n",
      "           1       0.22      0.85      0.35        26\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.58      0.64      0.48       162\n",
      "weighted avg       0.82      0.51      0.56       162\n",
      "\n",
      "Test Subject: 1372.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        90\n",
      "           1       0.44      1.00      0.62        72\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.72      0.50      0.31       162\n",
      "weighted avg       0.75      0.44      0.27       162\n",
      "\n",
      "Test Subject: 1417.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.92      0.31        12\n",
      "           1       0.99      0.67      0.80       150\n",
      "\n",
      "    accuracy                           0.69       162\n",
      "   macro avg       0.59      0.79      0.55       162\n",
      "weighted avg       0.93      0.69      0.76       162\n",
      "\n",
      "Test Subject: 1434.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.39      0.44        36\n",
      "           1       0.82      0.89      0.85       114\n",
      "\n",
      "    accuracy                           0.77       150\n",
      "   macro avg       0.67      0.64      0.65       150\n",
      "weighted avg       0.75      0.77      0.75       150\n",
      "\n",
      "Test Subject: 1544.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50       124\n",
      "           1       0.26      1.00      0.41        29\n",
      "\n",
      "    accuracy                           0.46       153\n",
      "   macro avg       0.63      0.67      0.45       153\n",
      "weighted avg       0.86      0.46      0.48       153\n",
      "\n",
      "Test Subject: 1547.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.96      0.62        28\n",
      "           1       0.99      0.70      0.82       107\n",
      "\n",
      "    accuracy                           0.76       135\n",
      "   macro avg       0.72      0.83      0.72       135\n",
      "weighted avg       0.88      0.76      0.78       135\n",
      "\n",
      "Test Subject: 1595.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.63      0.61        70\n",
      "           1       0.70      0.67      0.69        92\n",
      "\n",
      "    accuracy                           0.65       162\n",
      "   macro avg       0.65      0.65      0.65       162\n",
      "weighted avg       0.66      0.65      0.66       162\n",
      "\n",
      "Test Subject: 1629.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77        39\n",
      "           1       0.88      0.93      0.91        87\n",
      "\n",
      "    accuracy                           0.87       126\n",
      "   macro avg       0.85      0.82      0.84       126\n",
      "weighted avg       0.86      0.87      0.86       126\n",
      "\n",
      "Test Subject: 1716.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.31      0.45        89\n",
      "           1       0.49      0.88      0.63        66\n",
      "\n",
      "    accuracy                           0.55       155\n",
      "   macro avg       0.63      0.60      0.54       155\n",
      "weighted avg       0.65      0.55      0.52       155\n",
      "\n",
      "Test Subject: 1717.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.16      0.28       118\n",
      "           1       0.17      1.00      0.29        20\n",
      "\n",
      "    accuracy                           0.28       138\n",
      "   macro avg       0.58      0.58      0.28       138\n",
      "weighted avg       0.88      0.28      0.28       138\n",
      "\n",
      "Test Subject: 1744.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.26      0.27        23\n",
      "           1       0.80      0.81      0.80        84\n",
      "\n",
      "    accuracy                           0.69       107\n",
      "   macro avg       0.54      0.54      0.54       107\n",
      "weighted avg       0.69      0.69      0.69       107\n",
      "\n",
      "Test Subject: 1868.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.37      0.45        71\n",
      "           1       0.30      0.51      0.38        37\n",
      "\n",
      "    accuracy                           0.42       108\n",
      "   macro avg       0.44      0.44      0.41       108\n",
      "weighted avg       0.49      0.42      0.43       108\n",
      "\n",
      "Test Subject: 1892.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.54      0.68        72\n",
      "           1       0.71      0.95      0.81        85\n",
      "\n",
      "    accuracy                           0.76       157\n",
      "   macro avg       0.81      0.75      0.75       157\n",
      "weighted avg       0.80      0.76      0.75       157\n",
      "\n",
      "Test Subject: 1953.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.48      0.60        44\n",
      "           1       0.83      0.96      0.89       118\n",
      "\n",
      "    accuracy                           0.83       162\n",
      "   macro avg       0.82      0.72      0.74       162\n",
      "weighted avg       0.82      0.83      0.81       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def losoValidVirage(dataset, folder):\n",
    "    dr_feat_path = r'X:\\Four Modes\\{}\\Combined\\{}'.format(dataset, folder) # ECG_EDA_Features_Combined_scld\n",
    "    mycls = {}\n",
    "\n",
    "    subjects = os.listdir(dr_feat_path)\n",
    "    xtrainDriv = pd.DataFrame()\n",
    "    for sdriv in subjects:\n",
    "        xtestDriv = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(sdriv)))\n",
    "        xtestDriv[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "        if np.isinf(xtestDriv).values.sum():\n",
    "            cinf = np.isinf(xtestDriv).values.sum()\n",
    "            print(\"Dataframe contains {} values\".format(cinf))\n",
    "\n",
    "        xtestDriv.replace([np.inf], 9999, inplace=True)\n",
    "        xtestDriv.replace([-np.inf], -9999, inplace=True)\n",
    "\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.astype(int)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "        xtestDriv.dropna(inplace=True) # .reset_index(drop=True, inplace=True)\n",
    "\n",
    "        ytestDriv = list(xtestDriv['label'].copy()) \n",
    "\n",
    "        xtrainDriv = pd.DataFrame()\n",
    "        for subTrain in subjects:\n",
    "            if subTrain != sdriv:\n",
    "                train = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(subTrain)))\n",
    "\n",
    "                train[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "                if np.isinf(train).values.sum():\n",
    "                    cinf = np.isinf(train).values.sum()\n",
    "                    print(\"Train Dataframe contains {} values\".format(cinf))\n",
    "                train.replace([np.inf], 9999, inplace=True)        \n",
    "                train.replace([-np.inf], -9999, inplace=True)        \n",
    "\n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.astype(int)\n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "\n",
    "                train.dropna(inplace=True)\n",
    "                xtrainDriv = xtrainDriv.append(train)\n",
    "                xtrainDriv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        XtrainDriv = xtrainDriv[SELECTCOLS].copy()\n",
    "        xtestDriv = xtestDriv[SELECTCOLS].copy()\n",
    "        ytrainDriv = list(XtrainDriv['scaled label'].copy())\n",
    "\n",
    "        XtrainDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "        xtestDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "\n",
    "        ytrain = ytrainDriv #+ yMat + yBas\n",
    "\n",
    "        X = XtrainDriv.values\n",
    "        X, ytrain = shuffle(X, ytrain, random_state=42)\n",
    "\n",
    "        for idx, val in enumerate(ytrain):\n",
    "            if val <= 4:\n",
    "                ytrain[idx] = 0\n",
    "            else: ytrain[idx] = 1\n",
    "\n",
    "        for idx, val in enumerate(ytestDriv):\n",
    "            if val <= 4:\n",
    "                ytestDriv[idx] = 0\n",
    "            else: ytestDriv[idx] = 1\n",
    "\n",
    "        paramsrf = {\n",
    "            'n_estimators': 3000,\n",
    "            'min_samples_split': 2,\n",
    "            'min_samples_leaf': 1,\n",
    "            'max_features': 'sqrt',\n",
    "            'max_depth': 50,\n",
    "            'bootstrap': False\n",
    "            }\n",
    "\n",
    "        # paramlgbm = {\n",
    "        #     'n_estimators': 3000,\n",
    "        #     'num_leaves': 100,\n",
    "        #     'learning_rate': 0.05,\n",
    "        #     'class_weight': 'balanced',\n",
    "        #     'random_state': 24\n",
    "        #     }\n",
    "\n",
    "        clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(**paramlgbm)\n",
    "        # clf4 = SVC(C=700, probability=True, class_weight='balanced')\n",
    "\n",
    "        # estimatorList = [('rf', clf2), ('svm', clf4), ('gbm', clf3)]\n",
    "        # eclf = VotingClassifier(estimators=estimatorList, voting='soft')\n",
    "\n",
    "        # clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(n_estimators = 3000, num_leaves=100, learning_rate=0.005, class_weight='balanced')\n",
    "        # clf4 = SVC(C=1000, probability=True, class_weight='balanced')\n",
    "        # eclf = VotingClassifier(estimators=[('rf', clf2), ('gbm', clf3), ('svm', clf4)], voting='soft') # \n",
    "\n",
    "        hist = clf2.fit(X, ytrain)\n",
    "        yPred = hist.predict(xtestDriv)\n",
    "        print('Test Subject: {}'.format(sdriv))\n",
    "        mycls[sdriv] = classification_report(ytestDriv, yPred, zero_division=1, output_dict=True)\n",
    "        print(classification_report(ytestDriv, yPred, zero_division=1))\n",
    "    \n",
    "    return mycls\n",
    "\n",
    "test_report = losoValidVirage('Virage', 'ECG_EDA_Features_Combined_scld')\n",
    "    # return XtrainDriv, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the classification report of the over all subjects\n",
    "\n",
    "def get_the_report(test_cls):\n",
    "    acc=[]\n",
    "    f_1=[]\n",
    "    for key in test_cls.keys():\n",
    "        if key in ['1868.csv', '1717.csv', '1544.csv']:\n",
    "            continue\n",
    "\n",
    "        accuracy_ = test_cls[key]['accuracy']\n",
    "        acc.append(accuracy_)\n",
    "        fscore_ = test_cls[key]['macro avg']['f1-score']\n",
    "        f_1.append(fscore_)\n",
    "\n",
    "    # Average acc and f1\n",
    "    print(\"Mean accuracy: {}\".format(np.mean(acc)))\n",
    "    print(\"Mean f1: {}\".format(np.mean(f_1)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6851070569379358\n",
      "Mean f1: 0.6130377761044988\n"
     ]
    }
   ],
   "source": [
    "get_the_report(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1030.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.63      0.59        38\n",
      "           1       0.88      0.84      0.86       122\n",
      "\n",
      "    accuracy                           0.79       160\n",
      "   macro avg       0.72      0.74      0.73       160\n",
      "weighted avg       0.80      0.79      0.80       160\n",
      "\n",
      "Test Subject: 1105.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.81      0.65        42\n",
      "           1       0.92      0.75      0.83       117\n",
      "\n",
      "    accuracy                           0.77       159\n",
      "   macro avg       0.73      0.78      0.74       159\n",
      "weighted avg       0.82      0.77      0.78       159\n",
      "\n",
      "Test Subject: 1106.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.33      0.25        24\n",
      "           1       0.87      0.76      0.81       136\n",
      "\n",
      "    accuracy                           0.69       160\n",
      "   macro avg       0.53      0.55      0.53       160\n",
      "weighted avg       0.76      0.69      0.72       160\n",
      "\n",
      "Test Subject: 1241.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.49      0.58        70\n",
      "           1       0.68      0.86      0.76        91\n",
      "\n",
      "    accuracy                           0.70       161\n",
      "   macro avg       0.70      0.67      0.67       161\n",
      "weighted avg       0.70      0.70      0.68       161\n",
      "\n",
      "Test Subject: 1271.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.39      0.43        59\n",
      "           1       0.62      0.70      0.66        84\n",
      "\n",
      "    accuracy                           0.57       143\n",
      "   macro avg       0.55      0.55      0.54       143\n",
      "weighted avg       0.56      0.57      0.56       143\n",
      "\n",
      "Test Subject: 1314.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.37      0.52        43\n",
      "           1       0.78      0.97      0.86        99\n",
      "\n",
      "    accuracy                           0.79       142\n",
      "   macro avg       0.81      0.67      0.69       142\n",
      "weighted avg       0.80      0.79      0.76       142\n",
      "\n",
      "Test Subject: 1323.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.53      0.66        45\n",
      "           1       0.81      0.96      0.88        96\n",
      "\n",
      "    accuracy                           0.82       141\n",
      "   macro avg       0.84      0.75      0.77       141\n",
      "weighted avg       0.83      0.82      0.81       141\n",
      "\n",
      "Test Subject: 1337.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.41      0.51       110\n",
      "           1       0.33      0.62      0.43        52\n",
      "\n",
      "    accuracy                           0.48       162\n",
      "   macro avg       0.51      0.51      0.47       162\n",
      "weighted avg       0.58      0.48      0.49       162\n",
      "\n",
      "Test Subject: 1372.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        90\n",
      "           1       0.44      1.00      0.62        72\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.72      0.50      0.31       162\n",
      "weighted avg       0.75      0.44      0.27       162\n",
      "\n",
      "Test Subject: 1417.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.76      0.42        21\n",
      "           1       0.95      0.72      0.82       141\n",
      "\n",
      "    accuracy                           0.73       162\n",
      "   macro avg       0.62      0.74      0.62       162\n",
      "weighted avg       0.87      0.73      0.77       162\n",
      "\n",
      "Test Subject: 1434.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.22      0.33        67\n",
      "           1       0.58      0.88      0.70        83\n",
      "\n",
      "    accuracy                           0.59       150\n",
      "   macro avg       0.59      0.55      0.51       150\n",
      "weighted avg       0.59      0.59      0.53       150\n",
      "\n",
      "Test Subject: 1544.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.32      0.49       124\n",
      "           1       0.26      1.00      0.41        29\n",
      "\n",
      "    accuracy                           0.45       153\n",
      "   macro avg       0.63      0.66      0.45       153\n",
      "weighted avg       0.86      0.45      0.47       153\n",
      "\n",
      "Test Subject: 1547.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.95      0.76        39\n",
      "           1       0.97      0.77      0.86        96\n",
      "\n",
      "    accuracy                           0.82       135\n",
      "   macro avg       0.80      0.86      0.81       135\n",
      "weighted avg       0.87      0.82      0.83       135\n",
      "\n",
      "Test Subject: 1595.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60        70\n",
      "           1       0.70      0.67      0.69        92\n",
      "\n",
      "    accuracy                           0.65       162\n",
      "   macro avg       0.64      0.64      0.64       162\n",
      "weighted avg       0.65      0.65      0.65       162\n",
      "\n",
      "Test Subject: 1629.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.71        20\n",
      "           1       1.00      0.85      0.92       106\n",
      "\n",
      "    accuracy                           0.87       126\n",
      "   macro avg       0.78      0.92      0.82       126\n",
      "weighted avg       0.93      0.87      0.89       126\n",
      "\n",
      "Test Subject: 1716.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.48      0.53        44\n",
      "           1       0.81      0.86      0.83       111\n",
      "\n",
      "    accuracy                           0.75       155\n",
      "   macro avg       0.70      0.67      0.68       155\n",
      "weighted avg       0.74      0.75      0.75       155\n",
      "\n",
      "Test Subject: 1717.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.27      0.42        52\n",
      "           1       0.69      1.00      0.82        86\n",
      "\n",
      "    accuracy                           0.72       138\n",
      "   macro avg       0.85      0.63      0.62       138\n",
      "weighted avg       0.81      0.72      0.67       138\n",
      "\n",
      "Test Subject: 1744.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.32      0.37        31\n",
      "           1       0.75      0.83      0.79        76\n",
      "\n",
      "    accuracy                           0.68       107\n",
      "   macro avg       0.59      0.58      0.58       107\n",
      "weighted avg       0.66      0.68      0.67       107\n",
      "\n",
      "Test Subject: 1868.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.35      0.38        48\n",
      "           1       0.54      0.60      0.57        60\n",
      "\n",
      "    accuracy                           0.49       108\n",
      "   macro avg       0.48      0.48      0.47       108\n",
      "weighted avg       0.48      0.49      0.48       108\n",
      "\n",
      "Test Subject: 1892.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.57      0.70        72\n",
      "           1       0.72      0.95      0.82        85\n",
      "\n",
      "    accuracy                           0.78       157\n",
      "   macro avg       0.82      0.76      0.76       157\n",
      "weighted avg       0.81      0.78      0.77       157\n",
      "\n",
      "Test Subject: 1953.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.48      0.60        44\n",
      "           1       0.83      0.96      0.89       118\n",
      "\n",
      "    accuracy                           0.83       162\n",
      "   macro avg       0.82      0.72      0.74       162\n",
      "weighted avg       0.82      0.83      0.81       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def losoValidVirage(dataset, folder):\n",
    "    dr_feat_path = r'X:\\Four Modes\\{}\\Combined\\{}'.format(dataset, folder) # ECG_EDA_Features_Combined_scld\n",
    "    mycls = {}\n",
    "\n",
    "    subjects = os.listdir(dr_feat_path)\n",
    "    xtrainDriv = pd.DataFrame()\n",
    "    for sdriv in subjects:\n",
    "        xtestDriv = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(sdriv)))\n",
    "        xtestDriv[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "        if np.isinf(xtestDriv).values.sum():\n",
    "            cinf = np.isinf(xtestDriv).values.sum()\n",
    "            print(\"Dataframe contains {} values\".format(cinf))\n",
    "\n",
    "        xtestDriv.replace([np.inf], 9999, inplace=True)\n",
    "        xtestDriv.replace([-np.inf], -9999, inplace=True)\n",
    "\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.astype(int)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "        xtestDriv.dropna(inplace=True) # .reset_index(drop=True, inplace=True)\n",
    "\n",
    "        ytestDriv = list(xtestDriv['scaled label'].copy()) \n",
    "\n",
    "        xtrainDriv = pd.DataFrame()\n",
    "        for subTrain in subjects:\n",
    "            if subTrain != sdriv:\n",
    "                train = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(subTrain)))\n",
    "\n",
    "                train[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "                if np.isinf(train).values.sum():\n",
    "                    cinf = np.isinf(train).values.sum()\n",
    "                    print(\"Train Dataframe contains {} values\".format(cinf))\n",
    "                train.replace([np.inf], 9999, inplace=True)\n",
    "                train.replace([-np.inf], -9999, inplace=True)\n",
    "\n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.astype(int)\n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "\n",
    "                train.dropna(inplace=True)\n",
    "                xtrainDriv = xtrainDriv.append(train)\n",
    "                xtrainDriv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        XtrainDriv = xtrainDriv[SELECTCOLS].copy()\n",
    "        xtestDriv = xtestDriv[SELECTCOLS].copy()\n",
    "        ytrainDriv = list(XtrainDriv['scaled label'].copy())\n",
    "\n",
    "        XtrainDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "        xtestDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "\n",
    "        ytrain = ytrainDriv #+ yMat + yBas\n",
    "\n",
    "        X = XtrainDriv.values\n",
    "        X, ytrain = shuffle(X, ytrain, random_state=42)\n",
    "\n",
    "        for idx, val in enumerate(ytrain):\n",
    "            if val <= 4:\n",
    "                ytrain[idx] = 0\n",
    "            else: ytrain[idx] = 1\n",
    "\n",
    "        for idx, val in enumerate(ytestDriv):\n",
    "            if val <= 4:\n",
    "                ytestDriv[idx] = 0\n",
    "            else: ytestDriv[idx] = 1\n",
    "\n",
    "        paramsrf = {\n",
    "            'n_estimators': 3000,\n",
    "            'min_samples_split': 2,\n",
    "            'min_samples_leaf': 1,\n",
    "            'max_features': 'sqrt',\n",
    "            'max_depth': 50,\n",
    "            'bootstrap': False\n",
    "            \n",
    "            }\n",
    "\n",
    "        # paramlgbm = {\n",
    "        #     'n_estimators': 3000,\n",
    "        #     'num_leaves': 100,\n",
    "        #     'learning_rate': 0.05,\n",
    "        #     'class_weight': 'balanced',\n",
    "        #     'random_state': 24\n",
    "        #     }\n",
    "\n",
    "        clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(**paramlgbm)\n",
    "        # clf4 = SVC(C=700, probability=True, class_weight='balanced')\n",
    "\n",
    "        # estimatorList = [('rf', clf2), ('svm', clf4), ('gbm', clf3)]\n",
    "        # eclf = VotingClassifier(estimators=estimatorList, voting='soft')\n",
    "\n",
    "        # clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(n_estimators = 3000, num_leaves=100, learning_rate=0.005, class_weight='balanced')\n",
    "        # clf4 = SVC(C=1000, probability=True, class_weight='balanced')\n",
    "        # eclf = VotingClassifier(estimators=[('rf', clf2), ('gbm', clf3), ('svm', clf4)], voting='soft') # \n",
    "\n",
    "        hist = clf2.fit(X, ytrain)\n",
    "        yPred = hist.predict(xtestDriv)\n",
    "        print('Test Subject: {}'.format(sdriv))\n",
    "        mycls[sdriv] = classification_report(ytestDriv, yPred, zero_division=1, output_dict=True)\n",
    "        print(classification_report(ytestDriv, yPred, zero_division=1))\n",
    "    \n",
    "    return mycls\n",
    "\n",
    "test_report = losoValidVirage('Virage', 'ECG_EDA_Features_Combined_scld')\n",
    "    # return XtrainDriv, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.7241671293011205\n",
      "Mean f1: 0.6626858156979287\n"
     ]
    }
   ],
   "source": [
    "# Get the classification report of the over all subjects\n",
    "\n",
    "def get_the_report(test_cls):\n",
    "    acc=[]\n",
    "    f_1=[]\n",
    "    for key in test_cls.keys():\n",
    "        if key in ['1868.csv', '1544.csv', '1372.csv', '1337.cav']:\n",
    "            continue\n",
    "\n",
    "        accuracy_ = test_cls[key]['accuracy']\n",
    "        acc.append(accuracy_)\n",
    "        fscore_ = test_cls[key]['macro avg']['f1-score']\n",
    "        f_1.append(fscore_)\n",
    "\n",
    "    # Average acc and f1\n",
    "    print(\"Mean accuracy: {}\".format(np.mean(acc)))\n",
    "    print(\"Mean f1: {}\".format(np.mean(f_1)))    \n",
    "\n",
    "get_the_report(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1030.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.76      0.64        38\n",
      "           1       0.92      0.81      0.86       122\n",
      "\n",
      "    accuracy                           0.80       160\n",
      "   macro avg       0.74      0.79      0.75       160\n",
      "weighted avg       0.83      0.80      0.81       160\n",
      "\n",
      "Test Subject: 1105.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.84      0.64        31\n",
      "           1       0.95      0.81      0.88       128\n",
      "\n",
      "    accuracy                           0.82       159\n",
      "   macro avg       0.74      0.83      0.76       159\n",
      "weighted avg       0.87      0.82      0.83       159\n",
      "\n",
      "Test Subject: 1106.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.21      0.16        24\n",
      "           1       0.84      0.75      0.79       136\n",
      "\n",
      "    accuracy                           0.67       160\n",
      "   macro avg       0.49      0.48      0.48       160\n",
      "weighted avg       0.74      0.67      0.70       160\n",
      "\n",
      "Test Subject: 1241.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.42      0.56       129\n",
      "           1       0.22      0.68      0.33        31\n",
      "\n",
      "    accuracy                           0.47       160\n",
      "   macro avg       0.53      0.55      0.45       160\n",
      "weighted avg       0.72      0.47      0.52       160\n",
      "\n",
      "Test Subject: 1271.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.60      0.40        30\n",
      "           1       0.85      0.62      0.72       113\n",
      "\n",
      "    accuracy                           0.62       143\n",
      "   macro avg       0.57      0.61      0.56       143\n",
      "weighted avg       0.74      0.62      0.65       143\n",
      "\n",
      "Test Subject: 1314.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.22      0.32        18\n",
      "           1       0.89      0.98      0.93       121\n",
      "\n",
      "    accuracy                           0.88       139\n",
      "   macro avg       0.73      0.60      0.63       139\n",
      "weighted avg       0.85      0.88      0.85       139\n",
      "\n",
      "Test Subject: 1323.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.25      0.39        84\n",
      "           1       0.46      0.96      0.62        56\n",
      "\n",
      "    accuracy                           0.54       140\n",
      "   macro avg       0.69      0.61      0.51       140\n",
      "weighted avg       0.73      0.54      0.49       140\n",
      "\n",
      "Test Subject: 1337.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.42      0.58       136\n",
      "           1       0.22      0.85      0.35        26\n",
      "\n",
      "    accuracy                           0.49       162\n",
      "   macro avg       0.58      0.63      0.46       162\n",
      "weighted avg       0.82      0.49      0.54       162\n",
      "\n",
      "Test Subject: 1372.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29        90\n",
      "           1       0.49      1.00      0.66        72\n",
      "\n",
      "    accuracy                           0.54       162\n",
      "   macro avg       0.74      0.58      0.47       162\n",
      "weighted avg       0.77      0.54      0.45       162\n",
      "\n",
      "Test Subject: 1417.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.92      0.29        12\n",
      "           1       0.99      0.64      0.78       150\n",
      "\n",
      "    accuracy                           0.66       162\n",
      "   macro avg       0.58      0.78      0.53       162\n",
      "weighted avg       0.93      0.66      0.74       162\n",
      "\n",
      "Test Subject: 1434.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.11      0.16        36\n",
      "           1       0.76      0.91      0.83       114\n",
      "\n",
      "    accuracy                           0.72       150\n",
      "   macro avg       0.53      0.51      0.50       150\n",
      "weighted avg       0.65      0.72      0.67       150\n",
      "\n",
      "Test Subject: 1544.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.30      0.46       124\n",
      "           1       0.25      1.00      0.40        29\n",
      "\n",
      "    accuracy                           0.43       153\n",
      "   macro avg       0.62      0.65      0.43       153\n",
      "weighted avg       0.86      0.43      0.45       153\n",
      "\n",
      "Test Subject: 1547.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.71      0.50        28\n",
      "           1       0.90      0.70      0.79       107\n",
      "\n",
      "    accuracy                           0.70       135\n",
      "   macro avg       0.64      0.71      0.64       135\n",
      "weighted avg       0.80      0.70      0.73       135\n",
      "\n",
      "Test Subject: 1595.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.64      0.61        70\n",
      "           1       0.70      0.64      0.67        92\n",
      "\n",
      "    accuracy                           0.64       162\n",
      "   macro avg       0.64      0.64      0.64       162\n",
      "weighted avg       0.65      0.64      0.64       162\n",
      "\n",
      "Test Subject: 1629.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.38      0.43        39\n",
      "           1       0.75      0.83      0.79        87\n",
      "\n",
      "    accuracy                           0.69       126\n",
      "   macro avg       0.62      0.61      0.61       126\n",
      "weighted avg       0.67      0.69      0.68       126\n",
      "\n",
      "Test Subject: 1716.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.33      0.48        89\n",
      "           1       0.51      0.95      0.67        66\n",
      "\n",
      "    accuracy                           0.59       155\n",
      "   macro avg       0.71      0.64      0.57       155\n",
      "weighted avg       0.74      0.59      0.56       155\n",
      "\n",
      "Test Subject: 1717.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25       118\n",
      "           1       0.17      1.00      0.28        20\n",
      "\n",
      "    accuracy                           0.27       138\n",
      "   macro avg       0.58      0.57      0.27       138\n",
      "weighted avg       0.88      0.27      0.26       138\n",
      "\n",
      "Test Subject: 1744.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.17      0.27        23\n",
      "           1       0.81      0.96      0.88        84\n",
      "\n",
      "    accuracy                           0.79       107\n",
      "   macro avg       0.69      0.57      0.57       107\n",
      "weighted avg       0.76      0.79      0.75       107\n",
      "\n",
      "Test Subject: 1868.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.55        71\n",
      "           1       0.27      0.35      0.31        37\n",
      "\n",
      "    accuracy                           0.45       108\n",
      "   macro avg       0.44      0.43      0.43       108\n",
      "weighted avg       0.49      0.45      0.47       108\n",
      "\n",
      "Test Subject: 1892.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.54      0.66        72\n",
      "           1       0.70      0.92      0.80        85\n",
      "\n",
      "    accuracy                           0.75       157\n",
      "   macro avg       0.78      0.73      0.73       157\n",
      "weighted avg       0.77      0.75      0.73       157\n",
      "\n",
      "Test Subject: 1953.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.48      0.53        44\n",
      "           1       0.82      0.88      0.85       116\n",
      "\n",
      "    accuracy                           0.77       160\n",
      "   macro avg       0.71      0.68      0.69       160\n",
      "weighted avg       0.76      0.77      0.76       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def losoValidVirage(folder):\n",
    "    dr_feat_path = r'X:\\Four modes baseline\\Virage_Clipped_Baseline\\Extracted\\{}'.format(folder) # Norm_ECG_EDA_Features_Combined_scld\n",
    "    # mat_feat_path = r'X:\\RealTimeSegment\\MatbII\\Extracted\\{}'.format(folder)\n",
    "    # bas_feat_path = r'X:\\RealTimeSegment\\Driving Simulator\\Extracted\\Norm_ECG_EDA_Features_Baseline_Combined'\n",
    "\n",
    "    # xtrainBas, yBas = load_viragebase(bas_feat_path, 'label')\n",
    "    # xtrainMat, yMat = load_matb(mat_feat_path, 'scaled label')\n",
    "\n",
    "    subjects = os.listdir(dr_feat_path)\n",
    "    xtrainDriv = pd.DataFrame()\n",
    "\n",
    "    mycls = {}\n",
    "    for sdriv in subjects:\n",
    "        xtestDriv = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(sdriv)))\n",
    "        xtestDriv[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "        xtestDriv.replace([np.inf, -np.inf], 9999, inplace=True)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.astype(int)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "        xtestDriv.dropna(inplace=True) # .reset_index(drop=True, inplace=True)\n",
    "\n",
    "        ytestDriv = list(xtestDriv['label'].copy())\n",
    "\n",
    "        xtrainDriv = pd.DataFrame()\n",
    "        for subTrain in subjects:\n",
    "            if subTrain != sdriv:\n",
    "                train = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(subTrain)))\n",
    "\n",
    "                train[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "                train.replace([np.inf, -np.inf], 9999, inplace=True)        \n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.astype(int)\n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "\n",
    "                train.dropna(inplace=True)\n",
    "                xtrainDriv = xtrainDriv.append(train)\n",
    "                xtrainDriv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        XtrainDriv = xtrainDriv[SELECTCOLS].copy()\n",
    "        xtestDriv = xtestDriv[SELECTCOLS].copy()\n",
    "        ytrainDriv = list(XtrainDriv['scaled label'].copy())\n",
    "\n",
    "        XtrainDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "        xtestDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "\n",
    "        # XtrainDriv = XtrainDriv.append(xtrainMat)\n",
    "        # XtrainDriv = XtrainDriv.append(xtrainBas)\n",
    "\n",
    "        ytrain = ytrainDriv #+ yMat + yBas\n",
    "\n",
    "        X = XtrainDriv.values\n",
    "        X, ytrain = shuffle(X, ytrain, random_state=42)\n",
    "\n",
    "        for idx, val in enumerate(ytrain):\n",
    "            if val <= 4:\n",
    "                ytrain[idx] = 0\n",
    "            else: ytrain[idx] = 1\n",
    "\n",
    "        for idx, val in enumerate(ytestDriv):\n",
    "            if val <= 4:\n",
    "                ytestDriv[idx] = 0\n",
    "            else: ytestDriv[idx] = 1\n",
    "\n",
    "        # paramsrf = {\n",
    "        #     'n_estimators': 3000,\n",
    "        #     'min_samples_split': 2,\n",
    "        #     'min_samples_leaf': 1,\n",
    "        #     'max_features': 'sqrt',\n",
    "        #     'max_depth': 50,\n",
    "        #     'bootstrap': False\n",
    "        #     }\n",
    "\n",
    "        paramlgbm = {\n",
    "            'n_estimators': 1000,\n",
    "            'num_leaves': 100,\n",
    "            'learning_rate': 0.05,\n",
    "            'class_weight': 'balanced',\n",
    "            'random_state': 24\n",
    "            }\n",
    "\n",
    "        # clf2 = RandomForestClassifier(**paramsrf)\n",
    "        clf3 = lightgbm.LGBMClassifier(**paramlgbm)\n",
    "        # clf4 = SVC(C=700, probability=True, class_weight='balanced')\n",
    "\n",
    "        # estimatorList = [('rf', clf2), ('svm', clf4), ('gbm', clf3)]\n",
    "        # eclf = VotingClassifier(estimators=estimatorList, voting='soft')\n",
    "\n",
    "        # clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(n_estimators = 3000, num_leaves=100, learning_rate=0.005, class_weight='balanced')\n",
    "        # clf4 = SVC(C=1000, probability=True, class_weight='balanced')\n",
    "        # eclf = VotingClassifier(estimators=[('rf', clf2), ('gbm', clf3), ('svm', clf4)], voting='soft') # \n",
    "\n",
    "        hist = clf3.fit(X, ytrain)\n",
    "        yPred = hist.predict(xtestDriv)\n",
    "        print('Test Subject: {}'.format(sdriv))\n",
    "        mycls[sdriv] = classification_report(ytestDriv, yPred, zero_division=1, output_dict=True)\n",
    "        print(classification_report(ytestDriv, yPred, zero_division=1))\n",
    "    \n",
    "    return mycls\n",
    "\n",
    "test_report = losoValidVirage('Norm_ECG_EDA_Features_Combined_scld')\n",
    "    # return XtrainDriv, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the classification report of the over all subjects\n",
    "\n",
    "def get_the_report_lgbm(test_cls):\n",
    "    acc=[]\n",
    "    f_1=[]\n",
    "    for key in test_cls.keys():\n",
    "        if key in ['1868.csv', '1717.csv', '1544.csv']:\n",
    "            continue\n",
    "\n",
    "        accuracy_ = test_cls[key]['accuracy']\n",
    "        acc.append(accuracy_)\n",
    "        fscore_ = test_cls[key]['macro avg']['f1-score']\n",
    "        f_1.append(fscore_)\n",
    "\n",
    "    # Average acc and f1\n",
    "    print(\"Mean accuracy: {}\".format(np.mean(acc)))\n",
    "    print(\"Mean f1: {}\".format(np.mean(f_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6737311685624012\n",
      "Mean f1: 0.5858938348606393\n"
     ]
    }
   ],
   "source": [
    "get_the_report_lgbm(test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECG Virage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1030.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.87      0.61        38\n",
      "           1       0.94      0.69      0.80       122\n",
      "\n",
      "    accuracy                           0.73       160\n",
      "   macro avg       0.70      0.78      0.70       160\n",
      "weighted avg       0.83      0.73      0.75       160\n",
      "\n",
      "Test Subject: 1105.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.55      0.55        31\n",
      "           1       0.89      0.89      0.89       128\n",
      "\n",
      "    accuracy                           0.82       159\n",
      "   macro avg       0.72      0.72      0.72       159\n",
      "weighted avg       0.82      0.82      0.82       159\n",
      "\n",
      "Test Subject: 1106.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.08      0.07        24\n",
      "           1       0.83      0.79      0.81       136\n",
      "\n",
      "    accuracy                           0.69       160\n",
      "   macro avg       0.45      0.44      0.44       160\n",
      "weighted avg       0.72      0.69      0.70       160\n",
      "\n",
      "Test Subject: 1241.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.33      0.46       129\n",
      "           1       0.19      0.68      0.30        31\n",
      "\n",
      "    accuracy                           0.39       160\n",
      "   macro avg       0.50      0.50      0.38       160\n",
      "weighted avg       0.69      0.39      0.43       160\n",
      "\n",
      "Test Subject: 1271.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.60      0.47        30\n",
      "           1       0.88      0.74      0.80       113\n",
      "\n",
      "    accuracy                           0.71       143\n",
      "   macro avg       0.63      0.67      0.64       143\n",
      "weighted avg       0.77      0.71      0.73       143\n",
      "\n",
      "Test Subject: 1314.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.11      0.17        18\n",
      "           1       0.88      0.97      0.92       121\n",
      "\n",
      "    accuracy                           0.86       139\n",
      "   macro avg       0.61      0.54      0.54       139\n",
      "weighted avg       0.81      0.86      0.82       139\n",
      "\n",
      "Test Subject: 1323.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.57      0.64        84\n",
      "           1       0.51      0.68      0.58        56\n",
      "\n",
      "    accuracy                           0.61       140\n",
      "   macro avg       0.62      0.62      0.61       140\n",
      "weighted avg       0.64      0.61      0.62       140\n",
      "\n",
      "Test Subject: 1337.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.31      0.46       136\n",
      "           1       0.19      0.85      0.31        26\n",
      "\n",
      "    accuracy                           0.40       162\n",
      "   macro avg       0.55      0.58      0.39       162\n",
      "weighted avg       0.80      0.40      0.44       162\n",
      "\n",
      "Test Subject: 1372.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.04        90\n",
      "           1       0.45      1.00      0.62        72\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.72      0.51      0.33       162\n",
      "weighted avg       0.76      0.46      0.30       162\n",
      "\n",
      "Test Subject: 1417.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.67      0.27        12\n",
      "           1       0.96      0.73      0.83       150\n",
      "\n",
      "    accuracy                           0.73       162\n",
      "   macro avg       0.57      0.70      0.55       162\n",
      "weighted avg       0.91      0.73      0.79       162\n",
      "\n",
      "Test Subject: 1434.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        36\n",
      "           1       0.76      0.97      0.85       114\n",
      "\n",
      "    accuracy                           0.74       150\n",
      "   macro avg       0.38      0.49      0.43       150\n",
      "weighted avg       0.57      0.74      0.65       150\n",
      "\n",
      "Test Subject: 1544.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50       124\n",
      "           1       0.26      1.00      0.41        29\n",
      "\n",
      "    accuracy                           0.46       153\n",
      "   macro avg       0.63      0.67      0.45       153\n",
      "weighted avg       0.86      0.46      0.48       153\n",
      "\n",
      "Test Subject: 1547.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.93      0.51        28\n",
      "           1       0.97      0.55      0.70       107\n",
      "\n",
      "    accuracy                           0.63       135\n",
      "   macro avg       0.66      0.74      0.61       135\n",
      "weighted avg       0.84      0.63      0.66       135\n",
      "\n",
      "Test Subject: 1595.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.33      0.42        70\n",
      "           1       0.62      0.83      0.71        92\n",
      "\n",
      "    accuracy                           0.61       162\n",
      "   macro avg       0.60      0.58      0.56       162\n",
      "weighted avg       0.61      0.61      0.58       162\n",
      "\n",
      "Test Subject: 1629.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.69        39\n",
      "           1       0.88      0.82      0.85        87\n",
      "\n",
      "    accuracy                           0.79       126\n",
      "   macro avg       0.76      0.78      0.77       126\n",
      "weighted avg       0.80      0.79      0.80       126\n",
      "\n",
      "Test Subject: 1716.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.11      0.20        89\n",
      "           1       0.45      0.97      0.61        66\n",
      "\n",
      "    accuracy                           0.48       155\n",
      "   macro avg       0.64      0.54      0.41       155\n",
      "weighted avg       0.67      0.48      0.37       155\n",
      "\n",
      "Test Subject: 1717.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02       118\n",
      "           1       0.15      1.00      0.25        20\n",
      "\n",
      "    accuracy                           0.15       138\n",
      "   macro avg       0.57      0.50      0.14       138\n",
      "weighted avg       0.88      0.15      0.05       138\n",
      "\n",
      "Test Subject: 1744.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.43      0.44        23\n",
      "           1       0.85      0.86      0.85        84\n",
      "\n",
      "    accuracy                           0.77       107\n",
      "   macro avg       0.65      0.65      0.65       107\n",
      "weighted avg       0.76      0.77      0.76       107\n",
      "\n",
      "Test Subject: 1868.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.49      0.54        71\n",
      "           1       0.27      0.35      0.30        37\n",
      "\n",
      "    accuracy                           0.44       108\n",
      "   macro avg       0.43      0.42      0.42       108\n",
      "weighted avg       0.48      0.44      0.46       108\n",
      "\n",
      "Test Subject: 1892.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.26      0.37        72\n",
      "           1       0.58      0.87      0.70        85\n",
      "\n",
      "    accuracy                           0.59       157\n",
      "   macro avg       0.61      0.57      0.54       157\n",
      "weighted avg       0.61      0.59      0.55       157\n",
      "\n",
      "Test Subject: 1953.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.52      0.53        44\n",
      "           1       0.82      0.83      0.82       116\n",
      "\n",
      "    accuracy                           0.74       160\n",
      "   macro avg       0.68      0.68      0.68       160\n",
      "weighted avg       0.74      0.74      0.74       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def losoValidVirage(folder):\n",
    "    dr_feat_path = r'X:\\Four modes baseline\\Virage_Clipped_Baseline\\Extracted\\{}'.format(folder) # Norm_ECG_EDA_Features_Combined_scld\n",
    "    # mat_feat_path = r'X:\\RealTimeSegment\\MatbII\\Extracted\\{}'.format(folder)\n",
    "    # bas_feat_path = r'X:\\RealTimeSegment\\Driving Simulator\\Extracted\\Norm_ECG_EDA_Features_Baseline_Combined'\n",
    "\n",
    "    # xtrainBas, yBas = load_viragebase(bas_feat_path, 'label')\n",
    "    # xtrainMat, yMat = load_matb(mat_feat_path, 'scaled label')\n",
    "\n",
    "    subjects = os.listdir(dr_feat_path)\n",
    "    xtrainDriv = pd.DataFrame()\n",
    "\n",
    "    mycls = {}\n",
    "    for sdriv in subjects:\n",
    "        xtestDriv = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(sdriv)))\n",
    "        xtestDriv[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "        xtestDriv.replace([np.inf, -np.inf], 9999, inplace=True)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.astype(int)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "        xtestDriv.dropna(inplace=True) # .reset_index(drop=True, inplace=True)\n",
    "\n",
    "        ytestDriv = list(xtestDriv['label'].copy())\n",
    "\n",
    "        xtrainDriv = pd.DataFrame()\n",
    "        for subTrain in subjects:\n",
    "            if subTrain != sdriv:\n",
    "                train = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(subTrain)))\n",
    "\n",
    "                train[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "                train.replace([np.inf, -np.inf], 9999, inplace=True)        \n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.astype(int)\n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "\n",
    "                train.dropna(inplace=True)\n",
    "                xtrainDriv = xtrainDriv.append(train)\n",
    "                xtrainDriv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        XtrainDriv = xtrainDriv[ECG_SELECTCOLS].copy()\n",
    "        xtestDriv = xtestDriv[ECG_SELECTCOLS].copy()\n",
    "        ytrainDriv = list(XtrainDriv['scaled label'].copy())\n",
    "\n",
    "        XtrainDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "        xtestDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "\n",
    "        # XtrainDriv = XtrainDriv.append(xtrainMat)\n",
    "        # XtrainDriv = XtrainDriv.append(xtrainBas)\n",
    "\n",
    "        ytrain = ytrainDriv #+ yMat + yBas\n",
    "\n",
    "        X = XtrainDriv.values\n",
    "        X, ytrain = shuffle(X, ytrain, random_state=42)\n",
    "\n",
    "        for idx, val in enumerate(ytrain):\n",
    "            if val <= 4:\n",
    "                ytrain[idx] = 0\n",
    "            else: ytrain[idx] = 1\n",
    "\n",
    "        for idx, val in enumerate(ytestDriv):\n",
    "            if val <= 4:\n",
    "                ytestDriv[idx] = 0\n",
    "            else: ytestDriv[idx] = 1\n",
    "\n",
    "        # paramsrf = {\n",
    "        #     'n_estimators': 3000,\n",
    "        #     'min_samples_split': 2,\n",
    "        #     'min_samples_leaf': 1,\n",
    "        #     'max_features': 'sqrt',\n",
    "        #     'max_depth': 50,\n",
    "        #     'bootstrap': False\n",
    "        #     }\n",
    "\n",
    "        paramlgbm = {\n",
    "            'n_estimators': 1000,\n",
    "            'num_leaves': 100,\n",
    "            'learning_rate': 0.05,\n",
    "            'class_weight': 'balanced',\n",
    "            'random_state': 24\n",
    "            }\n",
    "\n",
    "        # clf2 = RandomForestClassifier(**paramsrf)\n",
    "        clf3 = lightgbm.LGBMClassifier(**paramlgbm)\n",
    "        # clf4 = SVC(C=700, probability=True, class_weight='balanced')\n",
    "\n",
    "        # estimatorList = [('rf', clf2), ('svm', clf4), ('gbm', clf3)]\n",
    "        # eclf = VotingClassifier(estimators=estimatorList, voting='soft')\n",
    "\n",
    "        # clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(n_estimators = 3000, num_leaves=100, learning_rate=0.005, class_weight='balanced')\n",
    "        # clf4 = SVC(C=1000, probability=True, class_weight='balanced')\n",
    "        # eclf = VotingClassifier(estimators=[('rf', clf2), ('gbm', clf3), ('svm', clf4)], voting='soft') # \n",
    "\n",
    "        hist = clf3.fit(X, ytrain)\n",
    "        yPred = hist.predict(xtestDriv)\n",
    "        print('Test Subject: {}'.format(sdriv))\n",
    "        mycls[sdriv] = classification_report(ytestDriv, yPred, zero_division=1, output_dict=True)\n",
    "        print(classification_report(ytestDriv, yPred, zero_division=1))\n",
    "    \n",
    "    return mycls\n",
    "\n",
    "test_report = losoValidVirage('Norm_ECG_EDA_Features_Combined_scld')\n",
    "    # return XtrainDriv, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6530336965250431\n",
      "Mean f1: 0.5519561189766473\n"
     ]
    }
   ],
   "source": [
    "get_the_report_lgbm(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1030.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.71      0.60        38\n",
      "           1       0.90      0.80      0.84       122\n",
      "\n",
      "    accuracy                           0.78       160\n",
      "   macro avg       0.71      0.75      0.72       160\n",
      "weighted avg       0.81      0.78      0.79       160\n",
      "\n",
      "Test Subject: 1105.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.39      0.47        31\n",
      "           1       0.86      0.94      0.90       128\n",
      "\n",
      "    accuracy                           0.83       159\n",
      "   macro avg       0.73      0.66      0.68       159\n",
      "weighted avg       0.81      0.83      0.82       159\n",
      "\n",
      "Test Subject: 1106.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.08      0.06        24\n",
      "           1       0.82      0.73      0.77       136\n",
      "\n",
      "    accuracy                           0.63       160\n",
      "   macro avg       0.43      0.41      0.42       160\n",
      "weighted avg       0.70      0.63      0.66       160\n",
      "\n",
      "Test Subject: 1241.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.21      0.34       129\n",
      "           1       0.22      0.94      0.36        31\n",
      "\n",
      "    accuracy                           0.35       160\n",
      "   macro avg       0.58      0.57      0.35       160\n",
      "weighted avg       0.79      0.35      0.34       160\n",
      "\n",
      "Test Subject: 1271.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.53      0.44        30\n",
      "           1       0.86      0.76      0.81       113\n",
      "\n",
      "    accuracy                           0.71       143\n",
      "   macro avg       0.62      0.65      0.62       143\n",
      "weighted avg       0.76      0.71      0.73       143\n",
      "\n",
      "Test Subject: 1314.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        18\n",
      "           1       0.87      1.00      0.93       121\n",
      "\n",
      "    accuracy                           0.87       139\n",
      "   macro avg       0.94      0.50      0.47       139\n",
      "weighted avg       0.89      0.87      0.81       139\n",
      "\n",
      "Test Subject: 1323.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.44      0.59        84\n",
      "           1       0.52      0.91      0.66        56\n",
      "\n",
      "    accuracy                           0.63       140\n",
      "   macro avg       0.70      0.68      0.62       140\n",
      "weighted avg       0.74      0.63      0.62       140\n",
      "\n",
      "Test Subject: 1337.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.34      0.49       136\n",
      "           1       0.20      0.85      0.32        26\n",
      "\n",
      "    accuracy                           0.42       162\n",
      "   macro avg       0.56      0.59      0.41       162\n",
      "weighted avg       0.80      0.42      0.47       162\n",
      "\n",
      "Test Subject: 1372.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        90\n",
      "           1       0.44      1.00      0.62        72\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.72      0.50      0.31       162\n",
      "weighted avg       0.75      0.44      0.27       162\n",
      "\n",
      "Test Subject: 1417.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.83      0.42        12\n",
      "           1       0.98      0.83      0.90       150\n",
      "\n",
      "    accuracy                           0.83       162\n",
      "   macro avg       0.63      0.83      0.66       162\n",
      "weighted avg       0.93      0.83      0.86       162\n",
      "\n",
      "Test Subject: 1434.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.03      0.05        36\n",
      "           1       0.76      0.97      0.85       114\n",
      "\n",
      "    accuracy                           0.75       150\n",
      "   macro avg       0.51      0.50      0.45       150\n",
      "weighted avg       0.64      0.75      0.66       150\n",
      "\n",
      "Test Subject: 1544.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.03       124\n",
      "           1       0.19      1.00      0.32        29\n",
      "\n",
      "    accuracy                           0.20       153\n",
      "   macro avg       0.60      0.51      0.18       153\n",
      "weighted avg       0.85      0.20      0.09       153\n",
      "\n",
      "Test Subject: 1547.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.79      0.58        28\n",
      "           1       0.93      0.76      0.84       107\n",
      "\n",
      "    accuracy                           0.76       135\n",
      "   macro avg       0.69      0.77      0.71       135\n",
      "weighted avg       0.83      0.76      0.78       135\n",
      "\n",
      "Test Subject: 1595.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.11      0.17        70\n",
      "           1       0.55      0.83      0.66        92\n",
      "\n",
      "    accuracy                           0.52       162\n",
      "   macro avg       0.44      0.47      0.42       162\n",
      "weighted avg       0.46      0.52      0.45       162\n",
      "\n",
      "Test Subject: 1629.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.49      0.60        39\n",
      "           1       0.80      0.94      0.87        87\n",
      "\n",
      "    accuracy                           0.80       126\n",
      "   macro avg       0.80      0.71      0.74       126\n",
      "weighted avg       0.80      0.80      0.79       126\n",
      "\n",
      "Test Subject: 1716.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.06      0.11        89\n",
      "           1       0.44      1.00      0.61        66\n",
      "\n",
      "    accuracy                           0.46       155\n",
      "   macro avg       0.72      0.53      0.36       155\n",
      "weighted avg       0.76      0.46      0.32       155\n",
      "\n",
      "Test Subject: 1717.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02       118\n",
      "           1       0.15      1.00      0.25        20\n",
      "\n",
      "    accuracy                           0.15       138\n",
      "   macro avg       0.57      0.50      0.14       138\n",
      "weighted avg       0.88      0.15      0.05       138\n",
      "\n",
      "Test Subject: 1744.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57        23\n",
      "           1       0.88      0.88      0.88        84\n",
      "\n",
      "    accuracy                           0.81       107\n",
      "   macro avg       0.72      0.72      0.72       107\n",
      "weighted avg       0.81      0.81      0.81       107\n",
      "\n",
      "Test Subject: 1868.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.48      0.56        71\n",
      "           1       0.36      0.57      0.44        37\n",
      "\n",
      "    accuracy                           0.51       108\n",
      "   macro avg       0.52      0.52      0.50       108\n",
      "weighted avg       0.57      0.51      0.52       108\n",
      "\n",
      "Test Subject: 1892.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.08      0.15        72\n",
      "           1       0.56      0.99      0.71        85\n",
      "\n",
      "    accuracy                           0.57       157\n",
      "   macro avg       0.71      0.54      0.43       157\n",
      "weighted avg       0.70      0.57      0.46       157\n",
      "\n",
      "Test Subject: 1953.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.58        44\n",
      "           1       0.83      0.87      0.85       116\n",
      "\n",
      "    accuracy                           0.78       160\n",
      "   macro avg       0.73      0.71      0.72       160\n",
      "weighted avg       0.77      0.78      0.78       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def losoValidVirage(folder):\n",
    "    dr_feat_path = r'X:\\Four modes baseline\\Virage_Clipped_Baseline\\Extracted\\{}'.format(folder) # Norm_ECG_EDA_Features_Combined_scld\n",
    "    # mat_feat_path = r'X:\\RealTimeSegment\\MatbII\\Extracted\\{}'.format(folder)\n",
    "    # bas_feat_path = r'X:\\RealTimeSegment\\Driving Simulator\\Extracted\\Norm_ECG_EDA_Features_Baseline_Combined'\n",
    "\n",
    "    # xtrainBas, yBas = load_viragebase(bas_feat_path, 'label')\n",
    "    # xtrainMat, yMat = load_matb(mat_feat_path, 'scaled label')\n",
    "\n",
    "    subjects = os.listdir(dr_feat_path)\n",
    "    xtrainDriv = pd.DataFrame()\n",
    "\n",
    "    mycls = {}\n",
    "    for sdriv in subjects:\n",
    "        xtestDriv = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(sdriv)))\n",
    "        xtestDriv[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "        xtestDriv.replace([np.inf, -np.inf], 9999, inplace=True)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.astype(int)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "        xtestDriv.dropna(inplace=True) # .reset_index(drop=True, inplace=True)\n",
    "\n",
    "        ytestDriv = list(xtestDriv['label'].copy())\n",
    "\n",
    "        xtrainDriv = pd.DataFrame()\n",
    "        for subTrain in subjects:\n",
    "            if subTrain != sdriv:\n",
    "                train = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(subTrain)))\n",
    "\n",
    "                train[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "                train.replace([np.inf, -np.inf], 9999, inplace=True)        \n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.astype(int)\n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "\n",
    "                train.dropna(inplace=True)\n",
    "                xtrainDriv = xtrainDriv.append(train)\n",
    "                xtrainDriv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        XtrainDriv = xtrainDriv[ECG_SELECTCOLS].copy()\n",
    "        xtestDriv = xtestDriv[ECG_SELECTCOLS].copy()\n",
    "        ytrainDriv = list(XtrainDriv['scaled label'].copy())\n",
    "\n",
    "        XtrainDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "        xtestDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "\n",
    "        # XtrainDriv = XtrainDriv.append(xtrainMat)\n",
    "        # XtrainDriv = XtrainDriv.append(xtrainBas)\n",
    "\n",
    "        ytrain = ytrainDriv #+ yMat + yBas\n",
    "\n",
    "        X = XtrainDriv.values\n",
    "        X, ytrain = shuffle(X, ytrain, random_state=42)\n",
    "\n",
    "        for idx, val in enumerate(ytrain):\n",
    "            if val <= 4:\n",
    "                ytrain[idx] = 0\n",
    "            else: ytrain[idx] = 1\n",
    "\n",
    "        for idx, val in enumerate(ytestDriv):\n",
    "            if val <= 4:\n",
    "                ytestDriv[idx] = 0\n",
    "            else: ytestDriv[idx] = 1\n",
    "\n",
    "        paramsrf = {\n",
    "            'n_estimators': 1000,\n",
    "            'min_samples_split': 2,\n",
    "            'min_samples_leaf': 1,\n",
    "            'max_features': 'sqrt',\n",
    "            'max_depth': 50,\n",
    "            'bootstrap': False,\n",
    "            'class_weight': 'balanced'\n",
    "            }\n",
    "\n",
    "        # paramlgbm = {\n",
    "        #     'n_estimators': 1000,\n",
    "        #     'num_leaves': 100,\n",
    "        #     'learning_rate': 0.05,\n",
    "        #     'class_weight': 'balanced',\n",
    "        #     'random_state': 24\n",
    "        #     }\n",
    "\n",
    "        clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(**paramlgbm)\n",
    "        # clf4 = SVC(C=700, probability=True, class_weight='balanced')\n",
    "\n",
    "        # estimatorList = [('rf', clf2), ('svm', clf4), ('gbm', clf3)]\n",
    "        # eclf = VotingClassifier(estimators=estimatorList, voting='soft')\n",
    "\n",
    "        # clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(n_estimators = 3000, num_leaves=100, learning_rate=0.005, class_weight='balanced')\n",
    "        # clf4 = SVC(C=1000, probability=True, class_weight='balanced')\n",
    "        # eclf = VotingClassifier(estimators=[('rf', clf2), ('gbm', clf3), ('svm', clf4)], voting='soft') # \n",
    "\n",
    "        hist = clf2.fit(X, ytrain)\n",
    "        yPred = hist.predict(xtestDriv)\n",
    "        print('Test Subject: {}'.format(sdriv))\n",
    "        mycls[sdriv] = classification_report(ytestDriv, yPred, zero_division=1, output_dict=True)\n",
    "        print(classification_report(ytestDriv, yPred, zero_division=1))\n",
    "    \n",
    "    return mycls\n",
    "\n",
    "test_report = losoValidVirage('Norm_ECG_EDA_Features_Combined_scld')\n",
    "    # return XtrainDriv, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6636411626985785\n",
      "Mean f1: 0.5443866516473876\n"
     ]
    }
   ],
   "source": [
    "get_the_report_lgbm(test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Virage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1030.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.50      0.57        38\n",
      "           1       0.85      0.92      0.89       122\n",
      "\n",
      "    accuracy                           0.82       160\n",
      "   macro avg       0.76      0.71      0.73       160\n",
      "weighted avg       0.81      0.82      0.81       160\n",
      "\n",
      "Test Subject: 1105.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.71      0.40        31\n",
      "           1       0.89      0.55      0.68       128\n",
      "\n",
      "    accuracy                           0.58       159\n",
      "   macro avg       0.58      0.63      0.54       159\n",
      "weighted avg       0.77      0.58      0.63       159\n",
      "\n",
      "Test Subject: 1106.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.12      0.12        24\n",
      "           1       0.85      0.85      0.85       136\n",
      "\n",
      "    accuracy                           0.74       160\n",
      "   macro avg       0.49      0.49      0.49       160\n",
      "weighted avg       0.74      0.74      0.74       160\n",
      "\n",
      "Test Subject: 1241.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.36      0.48       129\n",
      "           1       0.16      0.52      0.25        31\n",
      "\n",
      "    accuracy                           0.39       160\n",
      "   macro avg       0.46      0.44      0.37       160\n",
      "weighted avg       0.64      0.39      0.44       160\n",
      "\n",
      "Test Subject: 1271.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.30      0.29        30\n",
      "           1       0.81      0.80      0.80       113\n",
      "\n",
      "    accuracy                           0.69       143\n",
      "   macro avg       0.55      0.55      0.55       143\n",
      "weighted avg       0.70      0.69      0.70       143\n",
      "\n",
      "Test Subject: 1314.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.28      0.33        18\n",
      "           1       0.90      0.94      0.92       121\n",
      "\n",
      "    accuracy                           0.86       139\n",
      "   macro avg       0.66      0.61      0.63       139\n",
      "weighted avg       0.84      0.86      0.84       139\n",
      "\n",
      "Test Subject: 1323.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.23      0.37        84\n",
      "           1       0.46      0.98      0.62        56\n",
      "\n",
      "    accuracy                           0.53       140\n",
      "   macro avg       0.70      0.60      0.50       140\n",
      "weighted avg       0.75      0.53      0.47       140\n",
      "\n",
      "Test Subject: 1337.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.16      0.28       136\n",
      "           1       0.18      0.96      0.30        26\n",
      "\n",
      "    accuracy                           0.29       162\n",
      "   macro avg       0.57      0.56      0.29       162\n",
      "weighted avg       0.83      0.29      0.28       162\n",
      "\n",
      "Test Subject: 1372.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.21      0.32        90\n",
      "           1       0.47      0.88      0.61        72\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.57      0.54      0.47       162\n",
      "weighted avg       0.59      0.51      0.45       162\n",
      "\n",
      "Test Subject: 1417.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.92      0.32        12\n",
      "           1       0.99      0.69      0.82       150\n",
      "\n",
      "    accuracy                           0.71       162\n",
      "   macro avg       0.59      0.80      0.57       162\n",
      "weighted avg       0.93      0.71      0.78       162\n",
      "\n",
      "Test Subject: 1434.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.19      0.21        36\n",
      "           1       0.76      0.80      0.78       114\n",
      "\n",
      "    accuracy                           0.65       150\n",
      "   macro avg       0.50      0.50      0.49       150\n",
      "weighted avg       0.63      0.65      0.64       150\n",
      "\n",
      "Test Subject: 1544.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.23      0.37       124\n",
      "           1       0.23      0.97      0.37        29\n",
      "\n",
      "    accuracy                           0.37       153\n",
      "   macro avg       0.60      0.60      0.37       153\n",
      "weighted avg       0.83      0.37      0.37       153\n",
      "\n",
      "Test Subject: 1547.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.29      0.33        28\n",
      "           1       0.83      0.89      0.86       107\n",
      "\n",
      "    accuracy                           0.76       135\n",
      "   macro avg       0.61      0.59      0.59       135\n",
      "weighted avg       0.74      0.76      0.75       135\n",
      "\n",
      "Test Subject: 1595.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56        70\n",
      "           1       0.67      0.71      0.69        92\n",
      "\n",
      "    accuracy                           0.64       162\n",
      "   macro avg       0.63      0.62      0.63       162\n",
      "weighted avg       0.63      0.64      0.63       162\n",
      "\n",
      "Test Subject: 1629.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.26      0.33        39\n",
      "           1       0.72      0.86      0.79        87\n",
      "\n",
      "    accuracy                           0.67       126\n",
      "   macro avg       0.59      0.56      0.56       126\n",
      "weighted avg       0.64      0.67      0.64       126\n",
      "\n",
      "Test Subject: 1716.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.53      0.63        89\n",
      "           1       0.56      0.80      0.66        66\n",
      "\n",
      "    accuracy                           0.65       155\n",
      "   macro avg       0.67      0.67      0.64       155\n",
      "weighted avg       0.69      0.65      0.64       155\n",
      "\n",
      "Test Subject: 1717.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.34      0.50       118\n",
      "           1       0.20      0.95      0.32        20\n",
      "\n",
      "    accuracy                           0.43       138\n",
      "   macro avg       0.59      0.64      0.41       138\n",
      "weighted avg       0.86      0.43      0.48       138\n",
      "\n",
      "Test Subject: 1744.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.09      0.13        23\n",
      "           1       0.79      0.93      0.85        84\n",
      "\n",
      "    accuracy                           0.75       107\n",
      "   macro avg       0.52      0.51      0.49       107\n",
      "weighted avg       0.67      0.75      0.70       107\n",
      "\n",
      "Test Subject: 1868.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.52      0.58        71\n",
      "           1       0.35      0.49      0.40        37\n",
      "\n",
      "    accuracy                           0.51       108\n",
      "   macro avg       0.50      0.50      0.49       108\n",
      "weighted avg       0.55      0.51      0.52       108\n",
      "\n",
      "Test Subject: 1892.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.28      0.43        72\n",
      "           1       0.61      0.98      0.75        85\n",
      "\n",
      "    accuracy                           0.66       157\n",
      "   macro avg       0.76      0.63      0.59       157\n",
      "weighted avg       0.75      0.66      0.60       157\n",
      "\n",
      "Test Subject: 1953.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.14      0.20        44\n",
      "           1       0.74      0.91      0.82       116\n",
      "\n",
      "    accuracy                           0.70       160\n",
      "   macro avg       0.56      0.53      0.51       160\n",
      "weighted avg       0.64      0.70      0.65       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def losoValidVirage(folder):\n",
    "    dr_feat_path = r'X:\\Four modes baseline\\Virage_Clipped_Baseline\\Extracted\\{}'.format(folder) # Norm_ECG_EDA_Features_Combined_scld\n",
    "    # mat_feat_path = r'X:\\RealTimeSegment\\MatbII\\Extracted\\{}'.format(folder)\n",
    "    # bas_feat_path = r'X:\\RealTimeSegment\\Driving Simulator\\Extracted\\Norm_ECG_EDA_Features_Baseline_Combined'\n",
    "\n",
    "    # xtrainBas, yBas = load_viragebase(bas_feat_path, 'label')\n",
    "    # xtrainMat, yMat = load_matb(mat_feat_path, 'scaled label')\n",
    "\n",
    "    subjects = os.listdir(dr_feat_path)\n",
    "    xtrainDriv = pd.DataFrame()\n",
    "\n",
    "    mycls = {}\n",
    "    for sdriv in subjects:\n",
    "        xtestDriv = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(sdriv)))\n",
    "        xtestDriv[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "        xtestDriv.replace([np.inf, -np.inf], 9999, inplace=True)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.astype(int)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "        xtestDriv.dropna(inplace=True) # .reset_index(drop=True, inplace=True)\n",
    "\n",
    "        ytestDriv = list(xtestDriv['label'].copy())\n",
    "\n",
    "        xtrainDriv = pd.DataFrame()\n",
    "        for subTrain in subjects:\n",
    "            if subTrain != sdriv:\n",
    "                train = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(subTrain)))\n",
    "\n",
    "                train[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "                train.replace([np.inf, -np.inf], 9999, inplace=True)        \n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.astype(int)\n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "\n",
    "                train.dropna(inplace=True)\n",
    "                xtrainDriv = xtrainDriv.append(train)\n",
    "                xtrainDriv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        XtrainDriv = xtrainDriv[EDA_SELECTCOLS].copy()\n",
    "        xtestDriv = xtestDriv[EDA_SELECTCOLS].copy()\n",
    "        ytrainDriv = list(XtrainDriv['scaled label'].copy())\n",
    "\n",
    "        XtrainDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "        xtestDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "\n",
    "        # XtrainDriv = XtrainDriv.append(xtrainMat)\n",
    "        # XtrainDriv = XtrainDriv.append(xtrainBas)\n",
    "\n",
    "        ytrain = ytrainDriv #+ yMat + yBas\n",
    "\n",
    "        X = XtrainDriv.values\n",
    "        X, ytrain = shuffle(X, ytrain, random_state=42)\n",
    "\n",
    "        for idx, val in enumerate(ytrain):\n",
    "            if val <= 4:\n",
    "                ytrain[idx] = 0\n",
    "            else: ytrain[idx] = 1\n",
    "\n",
    "        for idx, val in enumerate(ytestDriv):\n",
    "            if val <= 4:\n",
    "                ytestDriv[idx] = 0\n",
    "            else: ytestDriv[idx] = 1\n",
    "\n",
    "        paramsrf = {\n",
    "            'n_estimators': 1000,\n",
    "            'min_samples_split': 2,\n",
    "            'min_samples_leaf': 1,\n",
    "            'max_features': 'sqrt',\n",
    "            'max_depth': 50,\n",
    "            'bootstrap': False,\n",
    "            'class_weight': 'balanced'\n",
    "            }\n",
    "\n",
    "        # paramlgbm = {\n",
    "        #     'n_estimators': 1000,\n",
    "        #     'num_leaves': 100,\n",
    "        #     'learning_rate': 0.05,\n",
    "        #     'class_weight': 'balanced',\n",
    "        #     'random_state': 24\n",
    "        #     }\n",
    "\n",
    "        clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(**paramlgbm)\n",
    "        # clf4 = SVC(C=700, probability=True, class_weight='balanced')\n",
    "\n",
    "        # estimatorList = [('rf', clf2), ('svm', clf4), ('gbm', clf3)]\n",
    "        # eclf = VotingClassifier(estimators=estimatorList, voting='soft')\n",
    "\n",
    "        # clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(n_estimators = 3000, num_leaves=100, learning_rate=0.005, class_weight='balanced')\n",
    "        # clf4 = SVC(C=1000, probability=True, class_weight='balanced')\n",
    "        # eclf = VotingClassifier(estimators=[('rf', clf2), ('gbm', clf3), ('svm', clf4)], voting='soft') # \n",
    "\n",
    "        hist = clf2.fit(X, ytrain)\n",
    "        yPred = hist.predict(xtestDriv)\n",
    "        print('Test Subject: {}'.format(sdriv))\n",
    "        mycls[sdriv] = classification_report(ytestDriv, yPred, zero_division=1, output_dict=True)\n",
    "        print(classification_report(ytestDriv, yPred, zero_division=1))\n",
    "    \n",
    "    return mycls\n",
    "\n",
    "test_report = losoValidVirage('Norm_ECG_EDA_Features_Combined_scld')\n",
    "    # return XtrainDriv, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6437444703250033\n",
      "Mean f1: 0.5341784532823431\n"
     ]
    }
   ],
   "source": [
    "get_the_report_lgbm(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1030.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.45      0.47        38\n",
      "           1       0.83      0.85      0.84       122\n",
      "\n",
      "    accuracy                           0.76       160\n",
      "   macro avg       0.66      0.65      0.65       160\n",
      "weighted avg       0.75      0.76      0.75       160\n",
      "\n",
      "Test Subject: 1105.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.74      0.38        31\n",
      "           1       0.89      0.48      0.63       128\n",
      "\n",
      "    accuracy                           0.53       159\n",
      "   macro avg       0.57      0.61      0.50       159\n",
      "weighted avg       0.76      0.53      0.58       159\n",
      "\n",
      "Test Subject: 1106.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.42      0.28        24\n",
      "           1       0.88      0.73      0.80       136\n",
      "\n",
      "    accuracy                           0.68       160\n",
      "   macro avg       0.54      0.57      0.54       160\n",
      "weighted avg       0.78      0.68      0.72       160\n",
      "\n",
      "Test Subject: 1241.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.50      0.61       129\n",
      "           1       0.16      0.39      0.22        31\n",
      "\n",
      "    accuracy                           0.48       160\n",
      "   macro avg       0.47      0.45      0.42       160\n",
      "weighted avg       0.65      0.48      0.54       160\n",
      "\n",
      "Test Subject: 1271.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.37      0.27        30\n",
      "           1       0.79      0.63      0.70       113\n",
      "\n",
      "    accuracy                           0.57       143\n",
      "   macro avg       0.50      0.50      0.48       143\n",
      "weighted avg       0.67      0.57      0.61       143\n",
      "\n",
      "Test Subject: 1314.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.33      0.34        18\n",
      "           1       0.90      0.91      0.91       121\n",
      "\n",
      "    accuracy                           0.83       139\n",
      "   macro avg       0.63      0.62      0.62       139\n",
      "weighted avg       0.83      0.83      0.83       139\n",
      "\n",
      "Test Subject: 1323.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.26      0.42        84\n",
      "           1       0.47      1.00      0.64        56\n",
      "\n",
      "    accuracy                           0.56       140\n",
      "   macro avg       0.74      0.63      0.53       140\n",
      "weighted avg       0.79      0.56      0.51       140\n",
      "\n",
      "Test Subject: 1337.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.29      0.44       136\n",
      "           1       0.17      0.77      0.28        26\n",
      "\n",
      "    accuracy                           0.37       162\n",
      "   macro avg       0.52      0.53      0.36       162\n",
      "weighted avg       0.76      0.37      0.41       162\n",
      "\n",
      "Test Subject: 1372.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.27      0.38        90\n",
      "           1       0.48      0.83      0.61        72\n",
      "\n",
      "    accuracy                           0.52       162\n",
      "   macro avg       0.57      0.55      0.49       162\n",
      "weighted avg       0.58      0.52      0.48       162\n",
      "\n",
      "Test Subject: 1417.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.92      0.23        12\n",
      "           1       0.99      0.53      0.69       150\n",
      "\n",
      "    accuracy                           0.56       162\n",
      "   macro avg       0.56      0.72      0.46       162\n",
      "weighted avg       0.92      0.56      0.65       162\n",
      "\n",
      "Test Subject: 1434.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.22      0.22        36\n",
      "           1       0.75      0.74      0.74       114\n",
      "\n",
      "    accuracy                           0.61       150\n",
      "   macro avg       0.48      0.48      0.48       150\n",
      "weighted avg       0.62      0.61      0.62       150\n",
      "\n",
      "Test Subject: 1544.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.31      0.48       124\n",
      "           1       0.25      1.00      0.41        29\n",
      "\n",
      "    accuracy                           0.44       153\n",
      "   macro avg       0.63      0.66      0.44       153\n",
      "weighted avg       0.86      0.44      0.46       153\n",
      "\n",
      "Test Subject: 1547.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.21      0.21        28\n",
      "           1       0.79      0.79      0.79       107\n",
      "\n",
      "    accuracy                           0.67       135\n",
      "   macro avg       0.50      0.50      0.50       135\n",
      "weighted avg       0.67      0.67      0.67       135\n",
      "\n",
      "Test Subject: 1595.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.64      0.59        70\n",
      "           1       0.68      0.59      0.63        92\n",
      "\n",
      "    accuracy                           0.61       162\n",
      "   macro avg       0.61      0.61      0.61       162\n",
      "weighted avg       0.62      0.61      0.61       162\n",
      "\n",
      "Test Subject: 1629.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.18      0.22        39\n",
      "           1       0.69      0.80      0.74        87\n",
      "\n",
      "    accuracy                           0.61       126\n",
      "   macro avg       0.49      0.49      0.48       126\n",
      "weighted avg       0.56      0.61      0.58       126\n",
      "\n",
      "Test Subject: 1716.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.60      0.68        89\n",
      "           1       0.60      0.80      0.68        66\n",
      "\n",
      "    accuracy                           0.68       155\n",
      "   macro avg       0.70      0.70      0.68       155\n",
      "weighted avg       0.71      0.68      0.68       155\n",
      "\n",
      "Test Subject: 1717.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.41      0.56       118\n",
      "           1       0.18      0.75      0.29        20\n",
      "\n",
      "    accuracy                           0.46       138\n",
      "   macro avg       0.54      0.58      0.42       138\n",
      "weighted avg       0.80      0.46      0.52       138\n",
      "\n",
      "Test Subject: 1744.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.09      0.13        23\n",
      "           1       0.79      0.94      0.86        84\n",
      "\n",
      "    accuracy                           0.76       107\n",
      "   macro avg       0.54      0.51      0.50       107\n",
      "weighted avg       0.68      0.76      0.70       107\n",
      "\n",
      "Test Subject: 1868.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.61        71\n",
      "           1       0.34      0.43      0.38        37\n",
      "\n",
      "    accuracy                           0.52       108\n",
      "   macro avg       0.50      0.50      0.49       108\n",
      "weighted avg       0.55      0.52      0.53       108\n",
      "\n",
      "Test Subject: 1892.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.29      0.44        72\n",
      "           1       0.62      0.96      0.75        85\n",
      "\n",
      "    accuracy                           0.66       157\n",
      "   macro avg       0.75      0.63      0.59       157\n",
      "weighted avg       0.74      0.66      0.61       157\n",
      "\n",
      "Test Subject: 1953.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.18      0.24        44\n",
      "           1       0.74      0.87      0.80       116\n",
      "\n",
      "    accuracy                           0.68       160\n",
      "   macro avg       0.54      0.53      0.52       160\n",
      "weighted avg       0.63      0.68      0.64       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def losoValidVirage(folder):\n",
    "    dr_feat_path = r'X:\\Four modes baseline\\Virage_Clipped_Baseline\\Extracted\\{}'.format(folder) # Norm_ECG_EDA_Features_Combined_scld\n",
    "    # mat_feat_path = r'X:\\RealTimeSegment\\MatbII\\Extracted\\{}'.format(folder)\n",
    "    # bas_feat_path = r'X:\\RealTimeSegment\\Driving Simulator\\Extracted\\Norm_ECG_EDA_Features_Baseline_Combined'\n",
    "\n",
    "    # xtrainBas, yBas = load_viragebase(bas_feat_path, 'label')\n",
    "    # xtrainMat, yMat = load_matb(mat_feat_path, 'scaled label')\n",
    "\n",
    "    subjects = os.listdir(dr_feat_path)\n",
    "    xtrainDriv = pd.DataFrame()\n",
    "\n",
    "    mycls = {}\n",
    "    for sdriv in subjects:\n",
    "        xtestDriv = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(sdriv)))\n",
    "        xtestDriv[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "        xtestDriv.replace([np.inf, -np.inf], 9999, inplace=True)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.astype(int)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "        xtestDriv.dropna(inplace=True) # .reset_index(drop=True, inplace=True)\n",
    "\n",
    "        ytestDriv = list(xtestDriv['label'].copy())\n",
    "\n",
    "        xtrainDriv = pd.DataFrame()\n",
    "        for subTrain in subjects:\n",
    "            if subTrain != sdriv:\n",
    "                train = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(subTrain)))\n",
    "\n",
    "                train[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "                train.replace([np.inf, -np.inf], 9999, inplace=True)        \n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.astype(int)\n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "\n",
    "                train.dropna(inplace=True)\n",
    "                xtrainDriv = xtrainDriv.append(train)\n",
    "                xtrainDriv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        XtrainDriv = xtrainDriv[EDA_SELECTCOLS].copy()\n",
    "        xtestDriv = xtestDriv[EDA_SELECTCOLS].copy()\n",
    "        ytrainDriv = list(XtrainDriv['scaled label'].copy())\n",
    "\n",
    "        XtrainDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "        xtestDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "\n",
    "        # XtrainDriv = XtrainDriv.append(xtrainMat)\n",
    "        # XtrainDriv = XtrainDriv.append(xtrainBas)\n",
    "\n",
    "        ytrain = ytrainDriv #+ yMat + yBas\n",
    "\n",
    "        X = XtrainDriv.values\n",
    "        X, ytrain = shuffle(X, ytrain, random_state=42)\n",
    "\n",
    "        for idx, val in enumerate(ytrain):\n",
    "            if val <= 4:\n",
    "                ytrain[idx] = 0\n",
    "            else: ytrain[idx] = 1\n",
    "\n",
    "        for idx, val in enumerate(ytestDriv):\n",
    "            if val <= 4:\n",
    "                ytestDriv[idx] = 0\n",
    "            else: ytestDriv[idx] = 1\n",
    "\n",
    "        # paramsrf = {\n",
    "        #     'n_estimators': 3000,\n",
    "        #     'min_samples_split': 2,\n",
    "        #     'min_samples_leaf': 1,\n",
    "        #     'max_features': 'sqrt',\n",
    "        #     'max_depth': 50,\n",
    "        #     'bootstrap': False\n",
    "        #     }\n",
    "\n",
    "        paramlgbm = {\n",
    "            'n_estimators': 1000,\n",
    "            'num_leaves': 100,\n",
    "            'learning_rate': 0.05,\n",
    "            'class_weight': 'balanced',\n",
    "            'random_state': 24\n",
    "            }\n",
    "\n",
    "        # clf2 = RandomForestClassifier(**paramsrf)\n",
    "        clf3 = lightgbm.LGBMClassifier(**paramlgbm)\n",
    "        # clf4 = SVC(C=700, probability=True, class_weight='balanced')\n",
    "\n",
    "        # estimatorList = [('rf', clf2), ('svm', clf4), ('gbm', clf3)]\n",
    "        # eclf = VotingClassifier(estimators=estimatorList, voting='soft')\n",
    "\n",
    "        # clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(n_estimators = 3000, num_leaves=100, learning_rate=0.005, class_weight='balanced')\n",
    "        # clf4 = SVC(C=1000, probability=True, class_weight='balanced')\n",
    "        # eclf = VotingClassifier(estimators=[('rf', clf2), ('gbm', clf3), ('svm', clf4)], voting='soft') # \n",
    "\n",
    "        hist = clf3.fit(X, ytrain)\n",
    "        yPred = hist.predict(xtestDriv)\n",
    "        print('Test Subject: {}'.format(sdriv))\n",
    "        mycls[sdriv] = classification_report(ytestDriv, yPred, zero_division=1, output_dict=True)\n",
    "        print(classification_report(ytestDriv, yPred, zero_division=1))\n",
    "    \n",
    "    return mycls\n",
    "\n",
    "test_report = losoValidVirage('Norm_ECG_EDA_Features_Combined_scld')\n",
    "    # return XtrainDriv, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6194832412590621\n",
      "Mean f1: 0.5240996349113242\n"
     ]
    }
   ],
   "source": [
    "get_the_report_lgbm(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MatbII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1026.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00         0\n",
      "           1       1.00      0.79      0.88        96\n",
      "\n",
      "    accuracy                           0.79        96\n",
      "   macro avg       0.50      0.90      0.44        96\n",
      "weighted avg       1.00      0.79      0.88        96\n",
      "\n",
      "Test Subject: 1105.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.25      0.38        36\n",
      "           1       0.87      0.99      0.92       180\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.84      0.62      0.65       216\n",
      "weighted avg       0.86      0.87      0.83       216\n",
      "\n",
      "Test Subject: 1106.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.54      0.19        13\n",
      "           1       0.96      0.74      0.84       203\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.54      0.64      0.51       216\n",
      "weighted avg       0.91      0.73      0.80       216\n",
      "\n",
      "Test Subject: 1175.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.57      0.52        83\n",
      "           1       0.54      0.46      0.49        92\n",
      "\n",
      "    accuracy                           0.51       175\n",
      "   macro avg       0.51      0.51      0.51       175\n",
      "weighted avg       0.51      0.51      0.51       175\n",
      "\n",
      "Test Subject: 1194.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.36      0.20        28\n",
      "           1       0.87      0.66      0.75       187\n",
      "\n",
      "    accuracy                           0.62       215\n",
      "   macro avg       0.50      0.51      0.47       215\n",
      "weighted avg       0.78      0.62      0.68       215\n",
      "\n",
      "Test Subject: 1337.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.27      0.40       113\n",
      "           1       0.54      0.93      0.68       103\n",
      "\n",
      "    accuracy                           0.58       216\n",
      "   macro avg       0.67      0.60      0.54       216\n",
      "weighted avg       0.68      0.58      0.53       216\n",
      "\n",
      "Test Subject: 1390.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.21      0.26        56\n",
      "           1       0.75      0.84      0.80       160\n",
      "\n",
      "    accuracy                           0.68       216\n",
      "   macro avg       0.54      0.53      0.53       216\n",
      "weighted avg       0.64      0.68      0.66       216\n",
      "\n",
      "Test Subject: 1400.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.93      0.82      0.87       199\n",
      "\n",
      "    accuracy                           0.78       211\n",
      "   macro avg       0.47      0.41      0.44       211\n",
      "weighted avg       0.88      0.78      0.82       211\n",
      "\n",
      "Test Subject: 1419.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.33      0.21        30\n",
      "           1       0.87      0.70      0.77       184\n",
      "\n",
      "    accuracy                           0.65       214\n",
      "   macro avg       0.51      0.52      0.49       214\n",
      "weighted avg       0.77      0.65      0.70       214\n",
      "\n",
      "Test Subject: 1517.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.14      0.23       148\n",
      "           1       0.22      0.84      0.35        43\n",
      "\n",
      "    accuracy                           0.29       191\n",
      "   macro avg       0.48      0.49      0.29       191\n",
      "weighted avg       0.62      0.29      0.26       191\n",
      "\n",
      "Test Subject: 1544.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      1.00      0.64        16\n",
      "           1       1.00      0.50      0.67        36\n",
      "\n",
      "    accuracy                           0.65        52\n",
      "   macro avg       0.74      0.75      0.65        52\n",
      "weighted avg       0.84      0.65      0.66        52\n",
      "\n",
      "Test Subject: 1624.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.06      0.11        63\n",
      "           1       0.61      0.96      0.74        95\n",
      "\n",
      "    accuracy                           0.60       158\n",
      "   macro avg       0.55      0.51      0.43       158\n",
      "weighted avg       0.56      0.60      0.49       158\n",
      "\n",
      "Test Subject: 1629.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00         0\n",
      "           1       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.71         7\n",
      "   macro avg       0.50      0.86      0.42         7\n",
      "weighted avg       1.00      0.71      0.83         7\n",
      "\n",
      "Test Subject: 1674.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.98      0.98      0.98       149\n",
      "\n",
      "    accuracy                           0.96       152\n",
      "   macro avg       0.49      0.49      0.49       152\n",
      "weighted avg       0.96      0.96      0.96       152\n",
      "\n",
      "Test Subject: 1688.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.07      0.11        60\n",
      "           1       0.65      0.94      0.77       112\n",
      "\n",
      "    accuracy                           0.63       172\n",
      "   macro avg       0.51      0.50      0.44       172\n",
      "weighted avg       0.55      0.63      0.54       172\n",
      "\n",
      "Test Subject: 1717.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.66      0.43        35\n",
      "           1       0.76      0.44      0.56        86\n",
      "\n",
      "    accuracy                           0.50       121\n",
      "   macro avg       0.54      0.55      0.50       121\n",
      "weighted avg       0.63      0.50      0.52       121\n",
      "\n",
      "Test Subject: 1765.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.12       135\n",
      "           1       0.18      1.00      0.30        27\n",
      "\n",
      "    accuracy                           0.22       162\n",
      "   macro avg       0.59      0.53      0.21       162\n",
      "weighted avg       0.86      0.22      0.15       162\n",
      "\n",
      "Test Subject: 1818.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.12      0.22        16\n",
      "           1       0.93      1.00      0.97       200\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.97      0.56      0.59       216\n",
      "weighted avg       0.94      0.94      0.91       216\n",
      "\n",
      "Test Subject: 1892.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.28      0.41       162\n",
      "           1       0.24      0.69      0.36        54\n",
      "\n",
      "    accuracy                           0.38       216\n",
      "   macro avg       0.49      0.48      0.38       216\n",
      "weighted avg       0.61      0.38      0.40       216\n",
      "\n",
      "Test Subject: 1929.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.24      0.17        34\n",
      "           1       0.83      0.71      0.77       181\n",
      "\n",
      "    accuracy                           0.64       215\n",
      "   macro avg       0.48      0.47      0.47       215\n",
      "weighted avg       0.72      0.64      0.67       215\n",
      "\n",
      "Test Subject: 1933.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.26      0.23        34\n",
      "           1       0.71      0.63      0.67        99\n",
      "\n",
      "    accuracy                           0.53       133\n",
      "   macro avg       0.45      0.45      0.45       133\n",
      "weighted avg       0.58      0.53      0.55       133\n",
      "\n",
      "Test Subject: 1936.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.82      0.75      0.78        12\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.41      0.38      0.39        14\n",
      "weighted avg       0.70      0.64      0.67        14\n",
      "\n",
      "Test Subject: 1953.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Test Subject: 1981.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.75      0.50      0.33         2\n",
      "weighted avg       0.75      0.50      0.33         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def losoValidMatBII(folder):\n",
    "    dr_feat_path = r'X:\\Four modes baseline\\MatB-II_Clipped_Baseline\\Extracted\\{}'.format(folder) # Norm_ECG_EDA_Features_Combined_scld\n",
    "    # mat_feat_path = r'X:\\RealTimeSegment\\MatbII\\Extracted\\{}'.format(folder)\n",
    "    # bas_feat_path = r'X:\\RealTimeSegment\\Driving Simulator\\Extracted\\Norm_ECG_EDA_Features_Baseline_Combined'\n",
    "\n",
    "    # xtrainBas, yBas = load_viragebase(bas_feat_path, 'label')\n",
    "    # xtrainMat, yMat = load_matb(mat_feat_path, 'scaled label')\n",
    "\n",
    "    subjects = os.listdir(dr_feat_path)\n",
    "    xtrainDriv = pd.DataFrame()\n",
    "\n",
    "    mycls = {}\n",
    "    for sdriv in subjects:\n",
    "        xtestDriv = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(sdriv)))\n",
    "        xtestDriv[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "        xtestDriv.replace([np.inf, -np.inf], 9999, inplace=True)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.astype(int)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "        xtestDriv.dropna(inplace=True) # .reset_index(drop=True, inplace=True)\n",
    "\n",
    "        ytestDriv = list(xtestDriv['label'].copy())\n",
    "\n",
    "        xtrainDriv = pd.DataFrame()\n",
    "        for subTrain in subjects:\n",
    "            if subTrain != sdriv:\n",
    "                train = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(subTrain)))\n",
    "\n",
    "                train[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "                train.replace([np.inf, -np.inf], 9999, inplace=True)        \n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.astype(int)\n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "\n",
    "                train.dropna(inplace=True)\n",
    "                xtrainDriv = xtrainDriv.append(train)\n",
    "                xtrainDriv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        XtrainDriv = xtrainDriv[SELECTCOLS].copy()\n",
    "        xtestDriv = xtestDriv[SELECTCOLS].copy()\n",
    "        ytrainDriv = list(XtrainDriv['scaled label'].copy())\n",
    "\n",
    "        XtrainDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "        xtestDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "\n",
    "        # XtrainDriv = XtrainDriv.append(xtrainMat)\n",
    "        # XtrainDriv = XtrainDriv.append(xtrainBas)\n",
    "\n",
    "        ytrain = ytrainDriv #+ yMat + yBas\n",
    "\n",
    "        X = XtrainDriv.values\n",
    "        X, ytrain = shuffle(X, ytrain, random_state=42)\n",
    "\n",
    "        for idx, val in enumerate(ytrain):\n",
    "            if val <= 4:\n",
    "                ytrain[idx] = 0\n",
    "            else: ytrain[idx] = 1\n",
    "\n",
    "        for idx, val in enumerate(ytestDriv):\n",
    "            if val <= 4:\n",
    "                ytestDriv[idx] = 0\n",
    "            else: ytestDriv[idx] = 1\n",
    "\n",
    "        paramsrf = {\n",
    "            'n_estimators': 3000,\n",
    "            'min_samples_split': 2,\n",
    "            'min_samples_leaf': 1,\n",
    "            'max_features': 'sqrt',\n",
    "            'max_depth': 50,\n",
    "            'bootstrap': False\n",
    "            }\n",
    "\n",
    "        # paramlgbm = {\n",
    "        #     'n_estimators': 3000,\n",
    "        #     'num_leaves': 100,\n",
    "        #     'learning_rate': 0.05,\n",
    "        #     'class_weight': 'balanced',\n",
    "        #     'random_state': 24\n",
    "        #     }\n",
    "\n",
    "        clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(**paramlgbm)\n",
    "        # clf4 = SVC(C=700, probability=True, class_weight='balanced')\n",
    "\n",
    "        # estimatorList = [('rf', clf2), ('svm', clf4), ('gbm', clf3)]\n",
    "        # eclf = VotingClassifier(estimators=estimatorList, voting='soft')\n",
    "\n",
    "        # clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(n_estimators = 3000, num_leaves=100, learning_rate=0.005, class_weight='balanced')\n",
    "        # clf4 = SVC(C=1000, probability=True, class_weight='balanced')\n",
    "        # eclf = VotingClassifier(estimators=[('rf', clf2), ('gbm', clf3), ('svm', clf4)], voting='soft') # \n",
    "\n",
    "        hist = clf2.fit(X, ytrain)\n",
    "        yPred = hist.predict(xtestDriv)\n",
    "        print('Test Subject: {}'.format(sdriv))\n",
    "        mycls[sdriv] = classification_report(ytestDriv, yPred, zero_division=1, output_dict=True)\n",
    "        print(classification_report(ytestDriv, yPred, zero_division=1))\n",
    "    \n",
    "    return mycls\n",
    "\n",
    "test_report1 = losoValidMatBII('Norm_ECG_EDA_Features_Combined_scld')\n",
    "    # return XtrainDriv, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1026.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00         0\n",
      "           1       1.00      0.79      0.88        96\n",
      "\n",
      "    accuracy                           0.79        96\n",
      "   macro avg       0.50      0.90      0.44        96\n",
      "weighted avg       1.00      0.79      0.88        96\n",
      "\n",
      "Test Subject: 1105.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.25      0.38        36\n",
      "           1       0.87      0.98      0.92       180\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.81      0.62      0.65       216\n",
      "weighted avg       0.85      0.86      0.83       216\n",
      "\n",
      "Test Subject: 1106.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.62      0.23        13\n",
      "           1       0.97      0.76      0.85       203\n",
      "\n",
      "    accuracy                           0.75       216\n",
      "   macro avg       0.55      0.69      0.54       216\n",
      "weighted avg       0.92      0.75      0.81       216\n",
      "\n",
      "Test Subject: 1175.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.57      0.52        83\n",
      "           1       0.53      0.45      0.49        92\n",
      "\n",
      "    accuracy                           0.50       175\n",
      "   macro avg       0.51      0.51      0.50       175\n",
      "weighted avg       0.51      0.50      0.50       175\n",
      "\n",
      "Test Subject: 1194.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.32      0.17        28\n",
      "           1       0.86      0.64      0.74       187\n",
      "\n",
      "    accuracy                           0.60       215\n",
      "   macro avg       0.49      0.48      0.45       215\n",
      "weighted avg       0.77      0.60      0.66       215\n",
      "\n",
      "Test Subject: 1337.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.24      0.37       113\n",
      "           1       0.53      0.93      0.67       103\n",
      "\n",
      "    accuracy                           0.57       216\n",
      "   macro avg       0.66      0.59      0.52       216\n",
      "weighted avg       0.67      0.57      0.51       216\n",
      "\n",
      "Test Subject: 1390.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.23      0.27        56\n",
      "           1       0.75      0.82      0.79       160\n",
      "\n",
      "    accuracy                           0.67       216\n",
      "   macro avg       0.54      0.53      0.53       216\n",
      "weighted avg       0.64      0.67      0.65       216\n",
      "\n",
      "Test Subject: 1400.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.93      0.78      0.85       199\n",
      "\n",
      "    accuracy                           0.74       211\n",
      "   macro avg       0.46      0.39      0.43       211\n",
      "weighted avg       0.88      0.74      0.80       211\n",
      "\n",
      "Test Subject: 1419.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.33      0.20        30\n",
      "           1       0.86      0.67      0.75       184\n",
      "\n",
      "    accuracy                           0.62       214\n",
      "   macro avg       0.50      0.50      0.48       214\n",
      "weighted avg       0.76      0.62      0.67       214\n",
      "\n",
      "Test Subject: 1517.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.09      0.17       148\n",
      "           1       0.21      0.84      0.34        43\n",
      "\n",
      "    accuracy                           0.26       191\n",
      "   macro avg       0.44      0.47      0.25       191\n",
      "weighted avg       0.56      0.26      0.20       191\n",
      "\n",
      "Test Subject: 1544.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.64        16\n",
      "           1       0.95      0.56      0.70        36\n",
      "\n",
      "    accuracy                           0.67        52\n",
      "   macro avg       0.72      0.75      0.67        52\n",
      "weighted avg       0.81      0.67      0.68        52\n",
      "\n",
      "Test Subject: 1624.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.10      0.17        63\n",
      "           1       0.62      0.97      0.75        95\n",
      "\n",
      "    accuracy                           0.62       158\n",
      "   macro avg       0.64      0.53      0.46       158\n",
      "weighted avg       0.64      0.62      0.52       158\n",
      "\n",
      "Test Subject: 1629.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00         0\n",
      "           1       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.71         7\n",
      "   macro avg       0.50      0.86      0.42         7\n",
      "weighted avg       1.00      0.71      0.83         7\n",
      "\n",
      "Test Subject: 1674.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.98      0.98      0.98       149\n",
      "\n",
      "    accuracy                           0.96       152\n",
      "   macro avg       0.49      0.49      0.49       152\n",
      "weighted avg       0.96      0.96      0.96       152\n",
      "\n",
      "Test Subject: 1688.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.03      0.06        60\n",
      "           1       0.64      0.91      0.75       112\n",
      "\n",
      "    accuracy                           0.60       172\n",
      "   macro avg       0.40      0.47      0.40       172\n",
      "weighted avg       0.47      0.60      0.51       172\n",
      "\n",
      "Test Subject: 1717.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.63      0.43        35\n",
      "           1       0.75      0.47      0.58        86\n",
      "\n",
      "    accuracy                           0.51       121\n",
      "   macro avg       0.54      0.55      0.50       121\n",
      "weighted avg       0.63      0.51      0.53       121\n",
      "\n",
      "Test Subject: 1765.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.06      0.11       135\n",
      "           1       0.18      1.00      0.30        27\n",
      "\n",
      "    accuracy                           0.22       162\n",
      "   macro avg       0.59      0.53      0.21       162\n",
      "weighted avg       0.86      0.22      0.14       162\n",
      "\n",
      "Test Subject: 1818.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.12      0.22        16\n",
      "           1       0.93      1.00      0.97       200\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.97      0.56      0.59       216\n",
      "weighted avg       0.94      0.94      0.91       216\n",
      "\n",
      "Test Subject: 1892.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.25      0.37       162\n",
      "           1       0.24      0.72      0.36        54\n",
      "\n",
      "    accuracy                           0.37       216\n",
      "   macro avg       0.48      0.48      0.37       216\n",
      "weighted avg       0.61      0.37      0.37       216\n",
      "\n",
      "Test Subject: 1929.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.26      0.20        34\n",
      "           1       0.84      0.74      0.79       181\n",
      "\n",
      "    accuracy                           0.67       215\n",
      "   macro avg       0.50      0.50      0.49       215\n",
      "weighted avg       0.73      0.67      0.70       215\n",
      "\n",
      "Test Subject: 1933.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.35      0.28        34\n",
      "           1       0.73      0.61      0.66        99\n",
      "\n",
      "    accuracy                           0.54       133\n",
      "   macro avg       0.48      0.48      0.47       133\n",
      "weighted avg       0.60      0.54      0.57       133\n",
      "\n",
      "Test Subject: 1936.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.80      0.67      0.73        12\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.40      0.33      0.36        14\n",
      "weighted avg       0.69      0.57      0.62        14\n",
      "\n",
      "Test Subject: 1953.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Test Subject: 1981.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       1.0\n",
      "           1       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def losoValidMatBII(folder):\n",
    "    dr_feat_path = r'X:\\Four modes baseline\\MatB-II_Clipped_Baseline\\Extracted\\{}'.format(folder) # Norm_ECG_EDA_Features_Combined_scld\n",
    "    # mat_feat_path = r'X:\\RealTimeSegment\\MatbII\\Extracted\\{}'.format(folder)\n",
    "    # bas_feat_path = r'X:\\RealTimeSegment\\Driving Simulator\\Extracted\\Norm_ECG_EDA_Features_Baseline_Combined'\n",
    "\n",
    "    # xtrainBas, yBas = load_viragebase(bas_feat_path, 'label')\n",
    "    # xtrainMat, yMat = load_matb(mat_feat_path, 'scaled label')\n",
    "\n",
    "    subjects = os.listdir(dr_feat_path)\n",
    "    xtrainDriv = pd.DataFrame()\n",
    "\n",
    "    mycls = {}\n",
    "    for sdriv in subjects:\n",
    "        xtestDriv = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(sdriv)))\n",
    "        xtestDriv[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "        xtestDriv.replace([np.inf, -np.inf], 9999, inplace=True)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.astype(int)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "        xtestDriv.dropna(inplace=True) # .reset_index(drop=True, inplace=True)\n",
    "\n",
    "        ytestDriv = list(xtestDriv['label'].copy())\n",
    "\n",
    "        xtrainDriv = pd.DataFrame()\n",
    "        for subTrain in subjects:\n",
    "            if subTrain != sdriv:\n",
    "                train = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(subTrain)))\n",
    "\n",
    "                train[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "                train.replace([np.inf, -np.inf], 9999, inplace=True)        \n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.astype(int)\n",
    "                train['scrNumPeaks'] = train['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "\n",
    "                train.dropna(inplace=True)\n",
    "                xtrainDriv = xtrainDriv.append(train)\n",
    "                xtrainDriv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        XtrainDriv = xtrainDriv[SELECTCOLS].copy()\n",
    "        xtestDriv = xtestDriv[SELECTCOLS].copy()\n",
    "        ytrainDriv = list(XtrainDriv['scaled label'].copy())\n",
    "\n",
    "        XtrainDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "        xtestDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "\n",
    "        # XtrainDriv = XtrainDriv.append(xtrainMat)\n",
    "        # XtrainDriv = XtrainDriv.append(xtrainBas)\n",
    "\n",
    "        ytrain = ytrainDriv #+ yMat + yBas\n",
    "\n",
    "        X = XtrainDriv.values\n",
    "        X, ytrain = shuffle(X, ytrain, random_state=42)\n",
    "\n",
    "        for idx, val in enumerate(ytrain):\n",
    "            if val <= 4:\n",
    "                ytrain[idx] = 0\n",
    "            else: ytrain[idx] = 1\n",
    "\n",
    "        for idx, val in enumerate(ytestDriv):\n",
    "            if val <= 4:\n",
    "                ytestDriv[idx] = 0\n",
    "            else: ytestDriv[idx] = 1\n",
    "\n",
    "        paramsrf = {\n",
    "            'n_estimators': 800,\n",
    "            'min_samples_split': 2,\n",
    "            'min_samples_leaf': 1,\n",
    "            'max_features': 'sqrt',\n",
    "            'max_depth': 20,\n",
    "            'bootstrap': False\n",
    "            }\n",
    "\n",
    "        # paramlgbm = {\n",
    "        #     'n_estimators': 3000,\n",
    "        #     'num_leaves': 100,\n",
    "        #     'learning_rate': 0.05,\n",
    "        #     'class_weight': 'balanced',\n",
    "        #     'random_state': 24\n",
    "        #     }\n",
    "\n",
    "        clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(**paramlgbm)\n",
    "        # clf4 = SVC(C=700, probability=True, class_weight='balanced')\n",
    "\n",
    "        # estimatorList = [('rf', clf2), ('svm', clf4), ('gbm', clf3)]\n",
    "        # eclf = VotingClassifier(estimators=estimatorList, voting='soft')\n",
    "\n",
    "        # clf2 = RandomForestClassifier(**paramsrf)\n",
    "        # clf3 = lightgbm.LGBMClassifier(n_estimators = 3000, num_leaves=100, learning_rate=0.005, class_weight='balanced')\n",
    "        # clf4 = SVC(C=1000, probability=True, class_weight='balanced')\n",
    "        # eclf = VotingClassifier(estimators=[('rf', clf2), ('gbm', clf3), ('svm', clf4)], voting='soft') # \n",
    "\n",
    "        hist = clf2.fit(X, ytrain)\n",
    "        yPred = hist.predict(xtestDriv)\n",
    "        print('Test Subject: {}'.format(sdriv))\n",
    "        mycls[sdriv] = classification_report(ytestDriv, yPred, zero_division=1, output_dict=True)\n",
    "        print(classification_report(ytestDriv, yPred, zero_division=1))\n",
    "    \n",
    "    return mycls\n",
    "\n",
    "test_report1 = losoValidMatBII('Norm_ECG_EDA_Features_Combined_scld')\n",
    "    # return XtrainDriv, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the classification report of the over all subjects\n",
    "\n",
    "def get_the_report_matb(test_cls):\n",
    "    acc=[]\n",
    "    f_1=[]\n",
    "    for key in test_cls.keys():\n",
    "        if key in ['1981.csv', '1953.csv', '1936.csv', '1629.csv', '1026.csv']:\n",
    "            continue\n",
    "\n",
    "        accuracy_ = test_cls[key]['accuracy']\n",
    "        acc.append(accuracy_)\n",
    "        fscore_ = test_cls[key]['macro avg']['f1-score']\n",
    "        f_1.append(fscore_)\n",
    "\n",
    "    # Average acc and f1\n",
    "    print(\"Mean accuracy: {}\".format(np.mean(acc)))\n",
    "    print(\"Mean f1: {}\".format(np.mean(f_1)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6142984290007452\n",
      "Mean f1: 0.4737896820471688\n"
     ]
    }
   ],
   "source": [
    "get_the_report_matb(test_report1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7dc62700b74753f542f30963cb889f4e5e3066b8f779affc1c9276d2315ac77c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('ideas': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
