{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from main_utils_1 import mk_dirs\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the virage and matbII with the respective baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030\n",
      "1105\n",
      "1106\n",
      "1241\n",
      "1271\n",
      "1314\n",
      "1323\n",
      "1337\n",
      "1372\n",
      "1417\n",
      "1434\n",
      "1544\n",
      "1547\n",
      "1595\n",
      "1629\n",
      "1716\n",
      "1717\n",
      "1744\n",
      "1868\n",
      "1892\n",
      "1953\n"
     ]
    }
   ],
   "source": [
    "# normalization of new features extracted from EDA with the new baseline features!\n",
    "main_path = r\"X:\\Four modes baseline\\Virage_Clipped_Baseline\\Extracted\\ECG_EDA_Features\"\n",
    "\n",
    "base_path = r\"X:\\RealTimeSegment\\Driving Simulator\\Extracted\\ECG_EDA_baseline_oneline_std\"\n",
    "sess_base_path = r\"X:\\Four modes baseline\\Virage_Clipped_Baseline\\Extracted\\ECG_EDA_baseline_oneline_std\"\n",
    "\n",
    "savePath_individual_feat = r\"X:\\Four modes baseline\\Virage_Clipped_Baseline\\Extracted\\Norm_ECG_EDA_Features\"\n",
    "label_path = r\"X:\\IDEaS_2\\Driving Simulator\\Data\\New_Labels\"\n",
    "combined_feat = r\"X:\\Four modes baseline\\Virage_Clipped_Baseline\\Extracted\\Norm_ECG_EDA_Features_Combined\"\n",
    "\n",
    "subjects_id = os.listdir(main_path)\n",
    "\n",
    "for sub_id in subjects_id:\n",
    "    sub_path = os.path.join(main_path, sub_id)\n",
    "    dirlist = os.listdir(sub_path)\n",
    "    exp_id = [x for x in dirlist if '_featurs_' in x] # op: ['ecg_level_1.csv', 'ecg_level_2.csv', ...]\n",
    "    exp_id = [x.replace('.csv', '') for x in exp_id]\n",
    "    exp_id = [x.replace('ecg_featurs_', '') for x in exp_id]\n",
    "    exp_id = [x.replace('eda_featurs_', '') for x in exp_id]\n",
    "    exp_id = set(exp_id)\n",
    "\n",
    "    sub_id = int(sub_id)\n",
    "    print(sub_id)\n",
    "\n",
    "    ''' read 3 minutes baseline for each sub '''\n",
    "    ecg_base = os.path.join(base_path, str(sub_id), 'ecg_baseline_features_oneline.csv')\n",
    "    eda_base = os.path.join(base_path, str(sub_id), 'eda_baseline_features_oneline.csv')\n",
    "    df_baseline_ecg = pd.read_csv(ecg_base)\n",
    "    df_baseline_eda = pd.read_csv(eda_base)\n",
    "\n",
    "    ''' Add 'ecg_' to each column name for ECG features in 3min Baseline '''\n",
    "    ecg_base_cols = list(df_baseline_ecg.columns)\n",
    "    ecg_base_cols = [x.replace('ecg_', '') for x in ecg_base_cols]\n",
    "    ecg_base_cols = ['ecg_' + x  for x in ecg_base_cols]\n",
    "\n",
    "    df_baseline_ecg.columns = ecg_base_cols\n",
    "\n",
    "    label_dir = os.path.join(label_path, '{}.csv'.format(sub_id))\n",
    "    df_label = pd.read_csv(label_dir).add_prefix('label_')\n",
    "    df_label['label_time'] = df_label['label_time'].apply(lambda x: x - 10)\n",
    "\n",
    "    df_main = pd.DataFrame()\n",
    "    for e_id in exp_id:\n",
    "        try:\n",
    "            eda_path = os.path.join(sub_path, 'eda_featurs_{}.csv'.format(e_id))\n",
    "            ecg_path = os.path.join(sub_path, 'ecg_featurs_{}.csv'.format(e_id))\n",
    "\n",
    "            df_ecg = pd.read_csv(ecg_path)\n",
    "            df_eda = pd.read_csv(eda_path)\n",
    "\n",
    "            df_ecg.drop(columns=['sess_id', 'subj_id'], inplace=True)\n",
    "            df_eda.drop(columns=['sess_id', 'subj_id'], inplace=True)\n",
    "\n",
    "            # break\n",
    "            ecgTime = df_ecg['Timestamp'].copy()\n",
    "            edaTime = df_eda['Timestamp'].copy()\n",
    "\n",
    "            ''' Read the session based baseline for each subject and session '''\n",
    "            sess_path = os.path.join(sess_base_path, str(sub_id))\n",
    "            sess_ecg_baseline = os.path.join(sess_path, 'ecg_level{}_baseline_features_oneline.csv'.format(e_id))\n",
    "            sess_eda_baseline = os.path.join(sess_path, 'eda_level{}_baseline_features_oneline.csv'.format(e_id))\n",
    "            #### Replace the ecg_baseline and eda_baseline df if the session baseline exists!\n",
    "            if os.path.exists(sess_ecg_baseline) and os.path.exists(sess_eda_baseline):\n",
    "                df_baseline_ecg = pd.read_csv(sess_ecg_baseline)\n",
    "                df_baseline_eda = pd.read_csv(sess_eda_baseline)\n",
    "\n",
    "            df_ecg = df_ecg.sub(df_baseline_ecg.iloc[0])\n",
    "            df_ecg = df_ecg.div(df_baseline_ecg.iloc[0])\n",
    "            df_ecg['Timestamp'] = ecgTime\n",
    "\n",
    "            df_eda = df_eda.sub(df_baseline_eda.iloc[0])\n",
    "            df_eda = df_eda.div(df_baseline_eda.iloc[0])\n",
    "            df_eda['Timestamp'] = edaTime\n",
    "\n",
    "            df_label['label_com_level_1'] = [1] * len(df_label)\n",
    "            df_label['label_com_level_2'] = [2] * len(df_label)\n",
    "            df_label['label_com_level_3'] = [3] * len(df_label)\n",
    "            df_label['label_com_level_4'] = [4] * len(df_label)\n",
    "            df_label['label_com_level_5'] = [5] * len(df_label)\n",
    "            df_label['label_com_level_6'] = [6] * len(df_label)\n",
    "            df_label['label_com_level_7'] = [7] * len(df_label)\n",
    "            df_label['label_com_level_8'] = [8] * len(df_label)\n",
    "            df_label['label_com_level_9'] = [9] * len(df_label)\n",
    "            \n",
    "            # Extracting releveant label columns for each experiment\n",
    "            label_exp = ['label_', 'label_com_']\n",
    "            relevant_label_columns = [x + 'level_' + e_id for x in label_exp]\n",
    "            relevant_label_columns.append('label_time')\n",
    "            df_rel_label = df_label[relevant_label_columns].copy()\n",
    "            df_rel_label.columns = ['label', 'complexity', 'label_time']\n",
    "\n",
    "            df_ecg.index = df_ecg['Timestamp'].values\n",
    "            df_eda.index = df_eda['Timestamp'].values\n",
    "            # df_label = df_ecg['label'].copy()\n",
    "\n",
    "            df_ecg.drop(columns=['Timestamp'], inplace=True) # removing Timestamps columns from one of the DataFrames\n",
    "\n",
    "            merged = pd.concat([df_ecg, df_eda], axis = 1)\n",
    "            df_merged = pd.merge(merged, df_rel_label, left_on='Timestamp', right_on='label_time', how='left')\n",
    "            df_merged.drop(columns=['Timestamp', 'label_time'], inplace=True)\n",
    "\n",
    "            df_main = df_main.append(df_merged)\n",
    "            df_main = df_main.reset_index(drop=True)\n",
    "\n",
    "            indv_path = os.path.join(savePath_individual_feat, str(sub_id))\n",
    "            mk_dirs(indv_path)\n",
    "\n",
    "            df_merged.to_csv(os.path.join(indv_path, '{}.csv'.format(e_id)),\n",
    "                            index = False)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    \n",
    "    mk_dirs(combined_feat)\n",
    "    df_main.dropna(subset=['label'], inplace=True)\n",
    "    df_main.to_csv(os.path.join(combined_feat, '{}.csv'.format(sub_id)), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_labels(values, actual_bounds, desired_bounds=(1, 9)):\n",
    "    return [desired_bounds[0] + (x - actual_bounds[0]) * (desired_bounds[1] - desired_bounds[0]) / (actual_bounds[1] - actual_bounds[0]) for x in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Scaled labels in the csv files for each subject\n",
    "\n",
    "subFile = r\"X:\\Four modes baseline\\Virage_Clipped_Baseline\\Extracted\\Norm_ECG_EDA_Features_Combined\"\n",
    "subScldFile = r\"X:\\Four modes baseline\\Virage_Clipped_Baseline\\Extracted\\Norm_ECG_EDA_Features_Combined_scld\"\n",
    "\n",
    "desMin = 1\n",
    "desMax = 9\n",
    "\n",
    "subjects = os.listdir(subFile)\n",
    "\n",
    "subjects = [x.replace('.csv', '') for x in subjects]\n",
    "for subs in subjects:\n",
    "    try:\n",
    "        subPath = os.path.join(subFile, '{}.csv'.format(subs))\n",
    "\n",
    "        subDf = pd.read_csv(subPath)\n",
    "        subMax = subDf['label'].max()\n",
    "        subMin = subDf['label'].min()\n",
    "\n",
    "        scLab = normalize_labels(subDf['label'].values, (subMin, subMax), (desMin, desMax))\n",
    "        scLab = [round(x) for x in scLab]\n",
    "\n",
    "        subDf['scaled label'] = scLab\n",
    "        mk_dirs(subScldFile)\n",
    "        subDf.to_csv(os.path.join(subScldFile, '{}.csv'.format(subs)), index = False)\n",
    "    except FileNotFoundError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Didn't rung the below code # resused the previous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_path = r\"X:\\RealTimeSegment\\Driving Simulator\\Extracted\\ECG_EDA_baseline_Features\"\n",
    "# base_path = r\"X:\\RealTimeSegment\\Driving Simulator\\Extracted\\ECG_EDA_baseline_oneline_std\"\n",
    "# # base_path = r\"X:\\RealTimeSegment\\Driving Simulator\\Extracted\\ECG_EDA_baseline_oneline\"\n",
    "\n",
    "# savePath_individual_feat = r\"X:\\RealTimeSegment\\Driving Simulator\\Extracted\\Norm_ECG_EDA_Features_Baseline\"\n",
    "# label_path = r\"X:\\IDEaS_2\\Driving Simulator\\Data\\New_Labels\"\n",
    "# combined_feat = r\"X:\\RealTimeSegment\\Driving Simulator\\Extracted\\Norm_ECG_EDA_Features_Baseline_Combined\"\n",
    "\n",
    "# subjects_id = os.listdir(main_path)\n",
    "\n",
    "# for sub_id in subjects_id:\n",
    "#     sub_path = os.path.join(main_path, sub_id)\n",
    "#     dirlist = os.listdir(sub_path)\n",
    "#     # exp_id = [x for x in dirlist if '_featurs_' in x] # op: ['ecg_level_1.csv', 'ecg_level_2.csv', ...]\n",
    "#     # exp_id = [x.replace('.csv', '') for x in exp_id]\n",
    "#     # exp_id = [x.replace('ecg_baseline_', '') for x in exp_id]\n",
    "#     # exp_id = [x.replace('eda_baseline_', '') for x in exp_id]\n",
    "#     # exp_id = set(exp_id)\n",
    "#     exp_id = ['baseline']\n",
    "#     sub_id = int(sub_id)\n",
    "\n",
    "#     ecg_base = os.path.join(base_path, str(sub_id), 'ecg_baseline_features_oneline.csv')\n",
    "#     eda_base = os.path.join(base_path, str(sub_id), 'eda_baseline_features_oneline.csv')\n",
    "\n",
    "#     df_baseline_ecg = pd.read_csv(ecg_base)\n",
    "#     df_baseline_eda = pd.read_csv(eda_base)\n",
    "\n",
    "#     ecg_base_cols = list(df_baseline_ecg.columns)\n",
    "#     ecg_base_cols = [x.replace('ecg_', '') for x in ecg_base_cols]\n",
    "#     ecg_base_cols = ['ecg_' + x  for x in ecg_base_cols]\n",
    "\n",
    "#     df_baseline_ecg.columns = ecg_base_cols\n",
    "#     df_main = pd.DataFrame()\n",
    "#     # break\n",
    "\n",
    "#     for e_id in exp_id:\n",
    "#         try:\n",
    "#             eda_path = os.path.join(sub_path, 'eda_{}_featurs.csv'.format(e_id))\n",
    "#             ecg_path = os.path.join(sub_path, 'ecg_{}_featurs.csv'.format(e_id))\n",
    "\n",
    "#             df_ecg = pd.read_csv(ecg_path)\n",
    "#             df_eda = pd.read_csv(eda_path)\n",
    "\n",
    "#             # break\n",
    "#             df_ecg.drop(columns=['subj_id'], inplace=True)\n",
    "#             df_eda.drop(columns=['subj_id'], inplace=True)\n",
    "\n",
    "#             # break\n",
    "#             ecgTime = df_ecg['Timestamp'].copy()\n",
    "#             edaTime = df_eda['Timestamp'].copy()\n",
    "\n",
    "#             # df_ecg = df_ecg.sub(df_baseline_ecg.iloc[0])\n",
    "#             df_ecg = df_ecg.div(df_baseline_ecg.iloc[0])\n",
    "#             df_ecg['Timestamp'] = ecgTime\n",
    "\n",
    "#             # df_eda = df_eda.sub(df_baseline_eda.iloc[0])\n",
    "#             df_eda = df_eda.div(df_baseline_eda.iloc[0])\n",
    "#             df_eda['Timestamp'] = edaTime\n",
    "            \n",
    "#             df_ecg.index = df_ecg['Timestamp'].values\n",
    "#             df_eda.index = df_eda['Timestamp'].values\n",
    "#             # df_label = df_ecg['label'].copy()\n",
    "\n",
    "#             df_ecg.drop(columns=['Timestamp'], inplace=True) # removing Timestamps columns from one of the DataFrames\n",
    "\n",
    "#             merged = pd.concat([df_ecg, df_eda], axis = 1)\n",
    "#             merged['label'] = [0] * len(merged)\n",
    "#             merged['complexity'] = [0] * len(merged)\n",
    "\n",
    "#             # df_merged = pd.merge(merged, df_rel_label, left_on='Timestamp', right_on='label_time', how='left')\n",
    "#             merged.drop(columns=['Timestamp'], inplace=True)\n",
    "\n",
    "#             df_main = df_main.append(merged)\n",
    "#             df_main = df_main.reset_index(drop=True)\n",
    "\n",
    "#             # break\n",
    "#             indv_path = os.path.join(savePath_individual_feat, str(sub_id))\n",
    "#             mk_dirs(indv_path)\n",
    "\n",
    "#             merged.to_csv(os.path.join(indv_path, '{}.csv'.format(e_id)),\n",
    "#                             index = False)\n",
    "#         except FileNotFoundError as e:\n",
    "#             print(e)\n",
    "#             continue\n",
    "#     # break\n",
    "#     mk_dirs(combined_feat)\n",
    "#     df_main.dropna(subset=['label'], inplace=True)\n",
    "#     df_main.to_csv(os.path.join(combined_feat, '{}.csv'.format(sub_id)), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MatBII Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1105\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1106\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1175\n",
      "session baseline exists\n",
      "1194\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1337\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1390\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1400\n",
      "1419\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1517\n",
      "1544\n",
      "session baseline exists\n",
      "1624\n",
      "1629\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1674\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1688\n",
      "1717\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1765\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1818\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1892\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1929\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1933\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "session baseline exists\n",
      "1936\n",
      "1953\n",
      "session baseline exists\n",
      "1981\n",
      "session baseline exists\n"
     ]
    }
   ],
   "source": [
    "main_path = r\"X:\\Four modes baseline\\MatB-II_Clipped_Baseline\\Extracted\\ECG_EDA_Features\"\n",
    "base_path = r\"X:\\RealTimeSegment\\MatbII\\Extracted\\ECG_EDA_baseline_oneline_std\"\n",
    "sess_base_path = r\"X:\\Four modes baseline\\MatB-II_Clipped_Baseline\\Extracted\\ECG_EDA_baseline_oneline_std\"\n",
    "\n",
    "# base_path = r\"X:\\RealTimeSegment\\MatbII\\Extracted\\ECG_EDA_baseline_oneline\"\n",
    "\n",
    "\n",
    "savePath_individual_feat = r\"X:\\Four modes baseline\\MatB-II_Clipped_Baseline\\Extracted\\Norm_ECG_EDA_Features\"\n",
    "label_path = r\"X:\\IDEaS_2\\MATBII\\Data\\New_Labels_2\"\n",
    "combined_feat = r\"X:\\Four modes baseline\\MatB-II_Clipped_Baseline\\Extracted\\Norm_ECG_EDA_Features_Combined\"\n",
    "\n",
    "subjects_id = os.listdir(main_path)\n",
    "\n",
    "for sub_id in subjects_id:\n",
    "    sub_path = os.path.join(main_path, sub_id)\n",
    "    dirlist = os.listdir(sub_path)\n",
    "    exp_id = [x for x in dirlist if '_featurs_' in x] # op: ['ecg_level_1.csv', 'ecg_level_2.csv', ...]\n",
    "    exp_id = [x.replace('.csv', '') for x in exp_id]\n",
    "    exp_id = [x.replace('ecg_featurs_', '') for x in exp_id]\n",
    "    exp_id = [x.replace('eda_featurs_', '') for x in exp_id]\n",
    "    exp_id = set(exp_id)\n",
    "\n",
    "    sub_id = int(sub_id)\n",
    "    print(sub_id)\n",
    "\n",
    "    ecg_base = os.path.join(base_path, str(sub_id), 'ecg_baseline_features_oneline.csv')\n",
    "    eda_base = os.path.join(base_path, str(sub_id), 'eda_baseline_features_oneline.csv')\n",
    "\n",
    "    df_baseline_ecg = pd.read_csv(ecg_base)\n",
    "    df_baseline_eda = pd.read_csv(eda_base)\n",
    "\n",
    "    ecg_base_cols = list(df_baseline_ecg.columns)\n",
    "    ecg_base_cols = [x.replace('ecg_', '') for x in ecg_base_cols]\n",
    "    ecg_base_cols = ['ecg_' + x  for x in ecg_base_cols]\n",
    "\n",
    "    df_baseline_ecg.columns = ecg_base_cols\n",
    "\n",
    "    label_dir = os.path.join(label_path, '{}.csv'.format(sub_id))\n",
    "    df_label = pd.read_csv(label_dir).add_prefix('label_')\n",
    "    df_label['label_time'] = df_label['label_time'].apply(lambda x: x - 10)\n",
    "\n",
    "    # break\n",
    "    df_main = pd.DataFrame()\n",
    "    for e_id in exp_id:\n",
    "        try:\n",
    "            eda_path = os.path.join(sub_path, 'eda_featurs_{}.csv'.format(e_id))\n",
    "            ecg_path = os.path.join(sub_path, 'ecg_featurs_{}.csv'.format(e_id))\n",
    "\n",
    "            df_ecg = pd.read_csv(ecg_path)\n",
    "            df_eda = pd.read_csv(eda_path)\n",
    "\n",
    "            df_ecg.drop(columns=['sess_id', 'subj_id'], inplace=True)\n",
    "            df_eda.drop(columns=['sess_id', 'subj_id'], inplace=True)\n",
    "\n",
    "            ecgTime = df_ecg['Timestamp'].copy()\n",
    "            edaTime = df_eda['Timestamp'].copy()\n",
    "\n",
    "            ''' Read the session based baseline for each subject and session '''\n",
    "            sess_path = os.path.join(sess_base_path, str(sub_id))\n",
    "            sess_ecg_baseline = os.path.join(sess_path, 'ecg_exp{}_baseline_features_oneline.csv'.format(e_id))\n",
    "            sess_eda_baseline = os.path.join(sess_path, 'eda_exp{}_baseline_features_oneline.csv'.format(e_id))\n",
    "            #### Replace the ecg_baseline and eda_baseline df if the session baseline exists!\n",
    "            if os.path.exists(sess_ecg_baseline) and os.path.exists(sess_eda_baseline):\n",
    "                print('session baseline exists')\n",
    "                df_baseline_ecg = pd.read_csv(sess_ecg_baseline)\n",
    "                df_baseline_eda = pd.read_csv(sess_eda_baseline)            \n",
    "\n",
    "            df_ecg = df_ecg.sub(df_baseline_ecg.iloc[0])\n",
    "            df_ecg = df_ecg.div(df_baseline_ecg.iloc[0])\n",
    "            df_ecg['Timestamp'] = ecgTime\n",
    "\n",
    "            df_eda = df_eda.sub(df_baseline_eda.iloc[0])\n",
    "            df_eda = df_eda.div(df_baseline_eda.iloc[0])\n",
    "            df_eda['Timestamp'] = edaTime\n",
    "\n",
    "            # Extracting releveant label columns for each experiment\n",
    "            label_exp = ['label_', 'label_com_']\n",
    "            relevant_label_columns = [x + 'exp_' + e_id for x in label_exp]\n",
    "            relevant_label_columns.append('label_time')\n",
    "            df_rel_label = df_label[relevant_label_columns].copy()\n",
    "            df_rel_label.columns = ['label', 'complexity', 'label_time']\n",
    "\n",
    "            df_ecg.index = df_ecg['Timestamp'].values\n",
    "            df_eda.index = df_eda['Timestamp'].values\n",
    "            # df_label = df_ecg['label'].copy()\n",
    "\n",
    "            df_ecg.drop(columns=['Timestamp'], inplace=True) # removing Timestamps columns from one of the DataFrames\n",
    "\n",
    "            merged = pd.concat([df_ecg, df_eda], axis = 1)\n",
    "            df_merged = pd.merge(merged, df_rel_label, left_on='Timestamp', right_on='label_time', how='left')\n",
    "            df_merged.drop(columns=['Timestamp', 'label_time'], inplace=True)\n",
    "\n",
    "            df_main = df_main.append(df_merged)\n",
    "            df_main = df_main.reset_index(drop=True)\n",
    "\n",
    "            indv_path = os.path.join(savePath_individual_feat, str(sub_id))\n",
    "            mk_dirs(indv_path)\n",
    "\n",
    "            # break\n",
    "            df_merged.to_csv(os.path.join(indv_path, '{}.csv'.format(e_id)),\n",
    "                            index = False)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    # break\n",
    "    mk_dirs(combined_feat)\n",
    "    df_main.dropna(subset=['label'], inplace=True)\n",
    "    df_main.to_csv(os.path.join(combined_feat, '{}.csv'.format(sub_id)), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Scaled labels in the csv files for each subject\n",
    "\n",
    "subFile = r\"X:\\Four modes baseline\\MatB-II_Clipped_Baseline\\Extracted\\Norm_ECG_EDA_Features_Combined\"\n",
    "subScldFile = r\"X:\\Four modes baseline\\MatB-II_Clipped_Baseline\\Extracted\\Norm_ECG_EDA_Features_Combined_scld\"\n",
    "\n",
    "desMin = 1\n",
    "desMax = 9\n",
    "\n",
    "subjects = os.listdir(subFile)\n",
    "\n",
    "subjects = [x.replace('.csv', '') for x in subjects]\n",
    "for subs in subjects:\n",
    "    try:\n",
    "        subPath = os.path.join(subFile, '{}.csv'.format(subs))\n",
    "\n",
    "        subDf = pd.read_csv(subPath)\n",
    "        subMax = subDf['label'].max()\n",
    "        subMin = subDf['label'].min()\n",
    "\n",
    "        scLab = normalize_labels(subDf['label'].values, (subMin, subMax), (desMin, desMax))\n",
    "        scLab = [round(x) for x in scLab]\n",
    "\n",
    "        subDf['scaled label'] = scLab\n",
    "        mk_dirs(subScldFile)\n",
    "        subDf.to_csv(os.path.join(subScldFile, '{}.csv'.format(subs)), index = False)\n",
    "    except FileNotFoundError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7dc62700b74753f542f30963cb889f4e5e3066b8f779affc1c9276d2315ac77c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('ideas': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
