{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dated Started: 2021-08-23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing for Virage Experiment\n",
    "## Copied from MainClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../IDEaSv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import neurokit2 as nk\n",
    "from scipy.stats import skew, kurtosis, iqr\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from feat_functions.main_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecg_sub_func(df, ecg_sample_rt=512):\n",
    "    df.reset_index(drop=True, inplace=True) # resetting the index after dropping nan rows\n",
    "    # converting the timestamps to float to make the data timestamps consistent\n",
    "    df['Timestamp'] = df['Timestamp'].astype('float')\n",
    "\n",
    "    # creating a list of all timestamps that should have been there if there was no missing datapoints.\n",
    "    time_list = ([df.loc[0, 'Timestamp'] + (x * (1000/ecg_sample_rt)) for x in range(0, int((df.loc[df.index[-1], 'Timestamp'] - df.loc[0, 'Timestamp'])/(1000/ecg_sample_rt)) + 1)])\n",
    "    \n",
    "    # creating a dataframe from the time_list that has all the timestamps (missing + not missing)\n",
    "    df_ecg = pd.DataFrame(time_list, columns = ['timestamp'])\n",
    "\n",
    "    # rounding the timestamps to 1 place decimal as then it would be more easier to compare timestamps!\n",
    "    df_ecg['timestamp'] = df_ecg['timestamp'].round(decimals = 1)\n",
    "    df_ecg.index = df_ecg['timestamp'] # shifting the timestamps to index\n",
    "\n",
    "    df['Timestamp'] = df['Timestamp'].round(decimals = 1)\n",
    "    df.index = df['Timestamp']\n",
    "\n",
    "    df_new = pd.concat([df_ecg, df], axis = 1)\n",
    "    df_new.drop(columns = ['Timestamp'], inplace=True)\n",
    "    df_new.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return df_new.copy()\n",
    "\n",
    "def eda_sub_func(df, eda_sample_rt=128):\n",
    "    df.reset_index(drop=True, inplace=True) # resetting the index after dropping nan rows\n",
    "    # converting the timestamps to float to make the data timestamps consistent\n",
    "    df['Timestamp'] = df['Timestamp'].astype('float')\n",
    "\n",
    "    # creating a list of all timestamps that should have been there if there was no missing datapoints.\n",
    "    time_list = ([df.loc[0, 'Timestamp'] + (x * (1000/eda_sample_rt)) for x in range(0, int((df.loc[df.index[-1], 'Timestamp'] - df.loc[0, 'Timestamp'])/(1000/eda_sample_rt)) + 1)])\n",
    "    \n",
    "    # creating a dataframe from the time_list that has all the timestamps (missing + not missing)\n",
    "    df_eda = pd.DataFrame(time_list, columns = ['timestamp'])\n",
    "\n",
    "    # rounding the timestamps to 1 place decimal as then it would be more easier to compare timestamps!\n",
    "    df_eda['timestamp'] = df_eda['timestamp'].round(decimals = 1)\n",
    "    df_eda.index = df_eda['timestamp'] # shifting the timestamps to index\n",
    "\n",
    "    df['Timestamp'] = df['Timestamp'].round(decimals = 1)\n",
    "    df.index = df['Timestamp']\n",
    "\n",
    "    df_new = pd.concat([df_eda, df], axis = 1)\n",
    "    df_new.drop(columns = ['Timestamp'], inplace=True)\n",
    "    df_new.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return df_new.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing the imputation and cleaning the whole signal here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030\n",
      "1105\n",
      "1106\n",
      "1241\n",
      "1271\n",
      "1314\n",
      "1323\n",
      "1337\n",
      "1372\n",
      "1417\n",
      "1434\n",
      "1544\n",
      "1547\n",
      "1595\n",
      "1629\n",
      "1716\n",
      "1717\n",
      "1744\n",
      "1868\n",
      "1892\n",
      "1953\n"
     ]
    }
   ],
   "source": [
    "main_path = r\"X:\\IDEaS\\Driving Simulator\\Signals_cp\"\n",
    "save_pth = r'X:\\RealTimeSegment\\Driving Simulator\\Raw\\ECG_EDA_baseline'\n",
    "ecg_sample_rt = 512\n",
    "subjects_id = os.listdir(main_path)\n",
    "dirlist = os.listdir(os.path.join(main_path, subjects_id[0]))\n",
    "# exp_id = [x for x in dirlist if 'level_' in x] # op: ['level_1.csv', 'level_2.csv', ...]\n",
    "exp_id = ['baseline']\n",
    "\n",
    "rd_cols = ['Timestamp', 'ECG LL-RA CAL',\n",
    "           'ECG LA-RA CAL', 'ECG Vx-RL CAL']\n",
    "\n",
    "# for sub_id in subjects_id:\n",
    "for sub_id in subjects_id:\n",
    "    subject_path = os.path.join(main_path, sub_id)\n",
    "    print(sub_id)\n",
    "\n",
    "    for xid in exp_id:\n",
    "        try:\n",
    "            read_path = os.path.join(subject_path, '{}.csv'.format(xid))\n",
    "            df = pd.read_csv(read_path, skipinitialspace=True, usecols=rd_cols)\n",
    "\n",
    "            df.dropna(inplace=True) # removing all the nan rows\n",
    "\n",
    "            # Putting a check if the signal data is not present in the csv then skip that subject\n",
    "            if len(df) == 0:\n",
    "                print('Subject {} does not have signal data for session: {}'.format(sub_id, xid))\n",
    "                continue\n",
    "\n",
    "            # df_new = ecg_sub_func(df, ecg_sample_rt)\n",
    "\n",
    "            # num_drops = df_new['ECG LL-RA CAL'].isna().sum()\n",
    "            # if num_drops > len(df_new) * 0.05:\n",
    "            #     print(xid)\n",
    "            #     continue\n",
    "\n",
    "            # df_ecg_new = impute_ecg(df_new.copy())\n",
    "            \n",
    "            # # cleaning the ECG signals\n",
    "            # df_ecg_new = ecg_cleaner(df_ecg_new)\n",
    "            \n",
    "            # csv_path = r'X:\\IDEaS\\Driving Simulator\\Data\\Interpolated_ECG_EDA_baseline\\{}'.format(sub_id)\n",
    "            csv_path = os.path.join(save_pth, '{}'.format(sub_id))\n",
    "            mk_dirs(csv_path)\n",
    "            df.to_csv(os.path.join(csv_path, 'ecg_{}.csv'.format(xid)), index=False)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # exp_3 for subject 1674 was not recorded :(\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = r\"X:\\IDEaS\\Driving Simulator\\Signals_cp\"\n",
    "save_pth = r'X:\\RealTimeSegment\\Driving Simulator\\Raw\\ECG_EDA_baseline'\n",
    "eda_sample_rt = 128\n",
    "subjects_id = os.listdir(main_path)\n",
    "dirlist = os.listdir(os.path.join(main_path, subjects_id[0]))\n",
    "# exp_id = [x for x in dirlist if 'level_' in x] # op: ['level_1.csv', 'level_2.csv', ...]\n",
    "exp_id = ['baseline']\n",
    "\n",
    "rd_cols = ['Timestamp', 'GSR Conductance CAL']\n",
    "\n",
    "# for sub_id in subjects_id:\n",
    "for sub_id in subjects_id:\n",
    "    subject_path = os.path.join(main_path, sub_id)\n",
    "    # print(sub_id)\n",
    "\n",
    "    for xid in exp_id:\n",
    "        try:\n",
    "            read_path = os.path.join(subject_path, '{}.csv'.format(xid))\n",
    "            df = pd.read_csv(read_path, skipinitialspace=True, usecols=rd_cols)\n",
    "\n",
    "            df.dropna(inplace=True) # removing all the nan rows\n",
    "\n",
    "            # Putting a check if the signal data is not present in the csv then skip that subject\n",
    "            if len(df) == 0:\n",
    "                print('Subject {} does not have signal data for session: {}'.format(sub_id, xid))\n",
    "                continue\n",
    "\n",
    "            # df_new = eda_sub_func(df, eda_sample_rt)\n",
    "\n",
    "            # num_drops = df_new['GSR Conductance CAL'].isna().sum()\n",
    "            # if num_drops > len(df_new) * 0.05:\n",
    "            #     print(xid)\n",
    "            #     continue\n",
    "\n",
    "            # df_eda_new = impute_eda(df_new)\n",
    "            \n",
    "            # # cleaning the EDA signals\n",
    "            # df_eda_new = eda_cleaner(df_eda_new)\n",
    "            # df_eda_new = eda_decom(df_eda_new)\n",
    "\n",
    "            # csv_path = r'X:\\IDEaS\\Driving Simulator\\Data\\Interpolated_ECG_EDA_baseline\\{}'.format(sub_id)\n",
    "            csv_path = os.path.join(save_pth, '{}'.format(sub_id))\n",
    "            \n",
    "            mk_dirs(csv_path)\n",
    "            df.to_csv(os.path.join(csv_path, 'eda_{}.csv'.format(xid)), index=False)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # exp_3 for subject 1674 was not recorded :(\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing datapoints in ECG signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030\n",
      "1105\n",
      "1106\n",
      "1241\n",
      "1271\n",
      "1314\n",
      "1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\anaconda3\\envs\\ideas\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3169: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1337\n",
      "1372\n",
      "1417\n",
      "1434\n",
      "1544\n",
      "1547\n",
      "1595\n",
      "1629\n",
      "1716\n",
      "1717\n",
      "Subject 1717 does not have signal data for session: level_9.csv\n",
      "1744\n",
      "1868\n",
      "1892\n",
      "1953\n"
     ]
    }
   ],
   "source": [
    "main_path = r\"X:\\IDEaS\\Driving Simulator\\Signals_cp\"\n",
    "ecg_sample_rt = 512\n",
    "subjects_id = os.listdir(main_path)\n",
    "dirlist = os.listdir(os.path.join(main_path, subjects_id[0]))\n",
    "exp_id = [x for x in dirlist if 'level_' in x] # op: ['level_1.csv', 'level_2.csv', ...]\n",
    "\n",
    "rd_cols = ['Timestamp', 'ECG LL-RA CAL',\n",
    "           'ECG LA-RA CAL', 'ECG Vx-RL CAL']\n",
    "\n",
    "# for sub_id in subjects_id:\n",
    "for sub_id in subjects_id:\n",
    "    subject_path = os.path.join(main_path, sub_id)\n",
    "\n",
    "    print(sub_id)\n",
    "\n",
    "    for xid in exp_id:\n",
    "        try:\n",
    "            read_path = os.path.join(subject_path, '{}'.format(xid))\n",
    "            df = pd.read_csv(read_path, dtype='object')\n",
    "            if df.columns[0] == '#INFO':\n",
    "                df = pd.read_csv(read_path, skiprows = 32, skipinitialspace=True, usecols=rd_cols)\n",
    "            else: \n",
    "                df = pd.read_csv(read_path, usecols=rd_cols)\n",
    "\n",
    "            df.dropna(inplace=True) # removing all the nan rows\n",
    "\n",
    "            # Putting a check if the signal data is not present in the csv then skip that subject\n",
    "            if len(df) == 0:\n",
    "                print('Subject {} does not have signal data for session: {}'.format(sub_id, xid))\n",
    "                continue\n",
    "\n",
    "            # df_new = ecg_sub_func(df, ecg_sample_rt)\n",
    "\n",
    "            # num_drops = df_new['ECG LL-RA CAL'].isna().sum()\n",
    "\n",
    "            # if num_drops > len(df_new) * 0.05:\n",
    "            #     print(xid)\n",
    "            #     continue\n",
    "\n",
    "            # df_ecg_new = impute_ecg(df_new.copy())\n",
    "            \n",
    "            # # cleaning the ECG signals\n",
    "            # df_ecg_new_1 = ecg_cleaner(df_ecg_new.copy())\n",
    "            \n",
    "           \n",
    "            csv_path = r'X:\\RealTimeSegment\\Driving Simulator\\Raw\\ECG_EDA\\{}'.format(sub_id)\n",
    "            \n",
    "            mk_dirs(csv_path)\n",
    "\n",
    "            df.to_csv(os.path.join(csv_path, 'ecg_{}'.format(xid)), index=False)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # exp_3 for subject 1674 was not recorded :(\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Imputing missing values in EDA signal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030\n",
      "1105\n",
      "1106\n",
      "1241\n",
      "1271\n",
      "1314\n",
      "1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\anaconda3\\envs\\ideas\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3169: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1323 does not have signal data for session: level_6\n",
      "1337\n",
      "1372\n",
      "1417\n",
      "1434\n",
      "1544\n",
      "1547\n",
      "1595\n",
      "1629\n",
      "1716\n",
      "1717\n",
      "1744\n",
      "1868\n",
      "1892\n",
      "1953\n"
     ]
    }
   ],
   "source": [
    "main_path = r\"X:\\IDEaS\\Driving Simulator\\Signals_cp\"\n",
    "eda_sample_rt = 128\n",
    "subjects_id = os.listdir(main_path)\n",
    "\n",
    "\n",
    "rd_cols = ['Timestamp', 'GSR Conductance CAL']\n",
    "\n",
    "for sub_id in subjects_id:\n",
    "\n",
    "    dirlist = os.listdir(os.path.join(main_path, sub_id))\n",
    "    exp_id = [x for x in dirlist if 'level_' in x] # op: ['level_1.csv', 'level_2.csv', ...]    \n",
    "    exp_id = [x.replace('.csv', '') for x in exp_id]\n",
    "\n",
    "    subject_path = os.path.join(main_path, sub_id)\n",
    "    print(sub_id)\n",
    "\n",
    "    for xid in exp_id:\n",
    "        try:\n",
    "            read_path = os.path.join(subject_path, '{}.csv'.format(xid))\n",
    "            df = pd.read_csv(read_path, dtype='object')\n",
    "            if df.columns[0] == '#INFO':\n",
    "                df = pd.read_csv(read_path, skiprows = 32, skipinitialspace=True, usecols=rd_cols)\n",
    "            else: \n",
    "                df = pd.read_csv(read_path, usecols=rd_cols)\n",
    "            \n",
    "            df.dropna(inplace=True) # removing all the nan rows\n",
    "\n",
    "            # Putting a check if the signal data is not present in the csv then skip that subject\n",
    "            if len(df) == 0:\n",
    "                print('Subject {} does not have signal data for session: {}'.format(sub_id, xid))\n",
    "                continue\n",
    "\n",
    "            # df_new = eda_sub_func(df, eda_sample_rt)\n",
    "\n",
    "            # num_drops = df_new['GSR Conductance CAL'].isna().sum()\n",
    "\n",
    "            # if num_drops > len(df_new) * 0.05:\n",
    "            #     print(xid)\n",
    "            #     continue\n",
    "\n",
    "            # df_eda_new = impute_eda(df_new.copy())\n",
    "            \n",
    "            # # cleaning the EDA signals\n",
    "            # df_eda_new_1 = eda_cleaner(df_eda_new.copy())\n",
    "\n",
    "            # df_eda_new_2 = eda_decom(df_eda_new_1.copy())\n",
    "\n",
    "            csv_path = r'X:\\RealTimeSegment\\Driving Simulator\\Raw\\ECG_EDA\\{}'.format(sub_id)\n",
    "            \n",
    "            mk_dirs(csv_path)\n",
    "            df.to_csv(os.path.join(csv_path, 'eda_{}.csv'.format(xid)), index=False)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030\n",
      "1105\n",
      "1106\n",
      "1241\n",
      "1271\n",
      "1314\n",
      "1323\n",
      "1337\n",
      "1372\n",
      "1417\n",
      "1434\n",
      "1544\n",
      "1547\n",
      "1595\n",
      "1629\n",
      "1716\n",
      "1717\n",
      "1744\n",
      "1868\n",
      "1892\n",
      "1953\n"
     ]
    }
   ],
   "source": [
    "# Not run in this file\n",
    "\n",
    "# Preparing the labels\n",
    "main_path = r\"X:\\IDEaS\\Driving Simulator\\Data\\Interpolated_ECG_EDA\"\n",
    "subjects_id = os.listdir(main_path)\n",
    "label_path = r\"X:\\IDEaS\\Driving Simulator\\driving_sim_cog_cp.xlsx\"\n",
    "labels_dir = r\"X:\\IDEaS\\Driving Simulator\\Data\\New_Labels\"\n",
    "mk_dirs(labels_dir)\n",
    "read_cols = ['time', 'level_1', 'level_2', 'level_3', 'level_4',\n",
    " 'level_5', 'level_6', 'level_7', 'level_8', 'level_9']\n",
    "for subs in subjects_id:\n",
    "    print(subs)\n",
    "    sub_labels = pd.read_excel(label_path, sheet_name = str(subs), skiprows=1, names=read_cols)\n",
    "    # sub_labels.rename(columns = {'Unnamed: 0': 'time'}, inplace=True)\n",
    "    sub_labels[sub_labels.columns] = sub_labels[sub_labels.columns].replace(['na', 'no response', 'no rep', np.nan, 'red'], np.nan)\n",
    "\n",
    "    try:\n",
    "        df_labels = fill_multi(sub_labels, 'level_1')\n",
    "        df_labels = fill_multi(df_labels, 'level_2')\n",
    "        df_labels = fill_multi(df_labels, 'level_3')\n",
    "        df_labels = fill_multi(df_labels, 'level_4')\n",
    "        df_labels = fill_multi(df_labels, 'level_5')\n",
    "        df_labels = fill_multi(df_labels, 'level_6')\n",
    "        df_labels = fill_multi(df_labels, 'level_7')\n",
    "        df_labels = fill_multi(df_labels, 'level_8')\n",
    "        df_labels = fill_multi(df_labels, 'level_9')\n",
    "    except KeyError:\n",
    "        pass\n",
    "    df_labels = df_labels.replace(to_replace = [np.nan], method='bfill')\n",
    "    df_labels = df_labels.replace(to_replace = [np.nan], method='ffill')\n",
    "\n",
    "    df_labels.to_csv(os.path.join(labels_dir, '{}.csv'.format(subs)), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[0:1280])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7dc62700b74753f542f30963cb889f4e5e3066b8f779affc1c9276d2315ac77c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('ideas': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
